{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial",
      "provenance": [],
      "authorship_tag": "ABX9TyP/YeW5li2Zqj1DwPTgd1X3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/Web_scraping/blob/master/Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tFcQBi7t9bU1"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "pip install -qU scrapy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile quotes_spider.py\n",
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = 'quotes'\n",
        "    start_urls = ['https://quotes.toscrape.com/tag/humor/']\n",
        "\n",
        "    def parse(self, response):\n",
        "        for quote in response.css('div.quote'):\n",
        "            yield {\n",
        "                'author': quote.xpath('span/small/text()').get(),\n",
        "                'text': quote.css('span.text::text').get()\n",
        "            }\n",
        "\n",
        "        next_page = response.css('li.next a::attr(\"href\")').get()\n",
        "        if next_page is not None:\n",
        "            yield response.follow(next_page, self.parse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDDBjF019o71",
        "outputId": "f02b3664-27e2-4a7d-a145-28698009d603"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing quotes_spider.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "scrapy runspider quotes_spider.py -o quotes.jl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTGIArVO9tCh",
        "outputId": "b6ae0306-812f-450e-f7b9-c8c093a3da7b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-06 07:50:01 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: scrapybot)\n",
            "2022-06-06 07:50:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.13 (default, Apr 24 2022, 01:04:09) - [GCC 7.5.0], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Linux-5.4.188+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-06-06 07:50:01 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'SPIDER_LOADER_WARN_ONLY': True}\n",
            "2022-06-06 07:50:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2022-06-06 07:50:01 [scrapy.extensions.telnet] INFO: Telnet Password: c34a429bf5c64f1e\n",
            "2022-06-06 07:50:01 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2022-06-06 07:50:01 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-06-06 07:50:01 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-06-06 07:50:01 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-06-06 07:50:01 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-06-06 07:50:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2022-06-06 07:50:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-06-06 07:50:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/tag/humor/> (referer: None)\n",
            "2022-06-06 07:50:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
            "{'author': 'Jane Austen', 'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”'}\n",
            "2022-06-06 07:50:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
            "{'author': 'Steve Martin', 'text': '“A day without sunshine is like, you know, night.”'}\n",
            "2022-06-06 07:50:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
            "{'author': 'Garrison Keillor', 'text': '“Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.”'}\n",
            "2022-06-06 07:50:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
            "{'author': 'Jim Henson', 'text': '“Beauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.”'}\n",
            "2022-06-06 07:50:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
            "{'author': 'Charles M. Schulz', 'text': \"“All you need is love. But a little chocolate now and then doesn't hurt.”\"}\n",
            "2022-06-06 07:50:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
            "{'author': 'Suzanne Collins', 'text': \"“Remember, we're madly in love, so it's all right to kiss me anytime you feel like it.”\"}\n",
            "2022-06-06 07:50:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
            "{'author': 'Charles Bukowski', 'text': '“Some people never go crazy. What truly horrible lives they must lead.”'}\n",
            "2022-06-06 07:50:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
            "{'author': 'Terry Pratchett', 'text': '“The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.”'}\n",
            "2022-06-06 07:50:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
            "{'author': 'Dr. Seuss', 'text': '“Think left and think right and think low and think high. Oh, the thinks you can think up if only you try!”'}\n",
            "2022-06-06 07:50:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
            "{'author': 'George Carlin', 'text': '“The reason I talk to myself is because I’m the only one whose answers I accept.”'}\n",
            "2022-06-06 07:50:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/tag/humor/page/2/> (referer: https://quotes.toscrape.com/tag/humor/)\n",
            "2022-06-06 07:50:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/page/2/>\n",
            "{'author': 'W.C. Fields', 'text': '“I am free of all prejudice. I hate everyone equally. ”'}\n",
            "2022-06-06 07:50:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/page/2/>\n",
            "{'author': 'Jane Austen', 'text': \"“A lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.”\"}\n",
            "2022-06-06 07:50:03 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2022-06-06 07:50:03 [scrapy.extensions.feedexport] INFO: Stored jl feed (12 items) in: quotes.jl\n",
            "2022-06-06 07:50:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 514,\n",
            " 'downloader/request_count': 2,\n",
            " 'downloader/request_method_count/GET': 2,\n",
            " 'downloader/response_bytes': 15665,\n",
            " 'downloader/response_count': 2,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'elapsed_time_seconds': 1.277304,\n",
            " 'feedexport/success_count/FileFeedStorage': 1,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2022, 6, 6, 7, 50, 3, 216106),\n",
            " 'item_scraped_count': 12,\n",
            " 'log_count/DEBUG': 15,\n",
            " 'log_count/INFO': 11,\n",
            " 'memusage/max': 68337664,\n",
            " 'memusage/startup': 68337664,\n",
            " 'request_depth_max': 1,\n",
            " 'response_received_count': 2,\n",
            " 'scheduler/dequeued': 2,\n",
            " 'scheduler/dequeued/memory': 2,\n",
            " 'scheduler/enqueued': 2,\n",
            " 'scheduler/enqueued/memory': 2,\n",
            " 'start_time': datetime.datetime(2022, 6, 6, 7, 50, 1, 938802)}\n",
            "2022-06-06 07:50:03 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a project"
      ],
      "metadata": {
        "id": "F9AL5k0C9wOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "scrapy startproject tutorial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjPrLOnu9x3G",
        "outputId": "1e37b7cd-77f1-4746-934b-2a94d28e9418"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Scrapy project 'tutorial', using template directory '/usr/local/lib/python3.7/dist-packages/scrapy/templates/project', created in:\n",
            "    /content/tutorial\n",
            "\n",
            "You can start your first spider with:\n",
            "    cd tutorial\n",
            "    scrapy genspider example example.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tutorial/tutorial/spiders/quotes_spider.py\n",
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = \"quotes\"\n",
        "\n",
        "    def start_request(self):\n",
        "        urls = [\n",
        "            'https://quotes.toscrape.com/page/1/',\n",
        "            'https://quotes.toscrape.com/page/2/'\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        page = response.url.split(\"/\")[-2]\n",
        "        filename = f'quotes-{page}.html'\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(response.body)\n",
        "        self.log(f'Saved file {filename}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhiubCScAAL6",
        "outputId": "0861272b-4e63-4dee-f0a4-507bc45df89e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tutorial/tutorial/spiders/quotes_spider.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd tutorial\n",
        "scrapy crawl quotes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ck1_F6jFD53",
        "outputId": "5cdf3987-77bd-46c5-882f-919a9e7369b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-06 08:50:22 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: tutorial)\n",
            "2022-06-06 08:50:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.13 (default, Apr 24 2022, 01:04:09) - [GCC 7.5.0], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Linux-5.4.188+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-06-06 08:50:22 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'tutorial',\n",
            " 'NEWSPIDER_MODULE': 'tutorial.spiders',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['tutorial.spiders']}\n",
            "2022-06-06 08:50:22 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2022-06-06 08:50:22 [scrapy.extensions.telnet] INFO: Telnet Password: b48b38d66eda3573\n",
            "2022-06-06 08:50:22 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2022-06-06 08:50:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-06-06 08:50:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-06-06 08:50:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-06-06 08:50:23 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-06-06 08:50:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2022-06-06 08:50:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-06-06 08:50:23 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2022-06-06 08:50:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'elapsed_time_seconds': 0.002538,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2022, 6, 6, 8, 50, 23, 125990),\n",
            " 'log_count/DEBUG': 1,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 68100096,\n",
            " 'memusage/startup': 68100096,\n",
            " 'start_time': datetime.datetime(2022, 6, 6, 8, 50, 23, 123452)}\n",
            "2022-06-06 08:50:23 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tutorial/tutorial/spiders/quotes_spider.py\n",
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = \"quotes\"\n",
        "    start_urls = [\n",
        "        'https://quotes.toscrape.com/page/1/',\n",
        "        'https://quotes.toscrape.com/page/2/'\n",
        "    ]\n",
        "\n",
        "    def parse(self, response):\n",
        "        page = response.url.split(\"/\")[-2]\n",
        "        filename = f'quotes-{page}.html'\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(response.body)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIeH3gbpFNwQ",
        "outputId": "ceff3e8d-3eeb-4259-886b-37ac5f703a0f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tutorial/tutorial/spiders/quotes_spider.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd tutorial\n",
        "scrapy crawl quotes"
      ],
      "metadata": {
        "id": "CK4Jqzq1RkQr",
        "outputId": "861ac4f1-308e-4f94-e640-7d0a580a841e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-06 09:09:42 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: tutorial)\n",
            "2022-06-06 09:09:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.13 (default, Apr 24 2022, 01:04:09) - [GCC 7.5.0], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Linux-5.4.188+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-06-06 09:09:42 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'tutorial',\n",
            " 'NEWSPIDER_MODULE': 'tutorial.spiders',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['tutorial.spiders']}\n",
            "2022-06-06 09:09:42 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2022-06-06 09:09:42 [scrapy.extensions.telnet] INFO: Telnet Password: c6db0e87bf959172\n",
            "2022-06-06 09:09:42 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2022-06-06 09:09:42 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-06-06 09:09:42 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-06-06 09:09:42 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-06-06 09:09:42 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-06-06 09:09:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2022-06-06 09:09:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-06-06 09:09:43 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://quotes.toscrape.com/robots.txt> (referer: None)\n",
            "2022-06-06 09:09:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)\n",
            "2022-06-06 09:09:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/2/> (referer: None)\n",
            "2022-06-06 09:09:44 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2022-06-06 09:09:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 681,\n",
            " 'downloader/request_count': 3,\n",
            " 'downloader/request_method_count/GET': 3,\n",
            " 'downloader/response_bytes': 25579,\n",
            " 'downloader/response_count': 3,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'downloader/response_status_count/404': 1,\n",
            " 'elapsed_time_seconds': 1.697315,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2022, 6, 6, 9, 9, 44, 379645),\n",
            " 'log_count/DEBUG': 4,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 68759552,\n",
            " 'memusage/startup': 68759552,\n",
            " 'response_received_count': 3,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/404': 1,\n",
            " 'scheduler/dequeued': 2,\n",
            " 'scheduler/dequeued/memory': 2,\n",
            " 'scheduler/enqueued': 2,\n",
            " 'scheduler/enqueued/memory': 2,\n",
            " 'start_time': datetime.datetime(2022, 6, 6, 9, 9, 42, 682330)}\n",
            "2022-06-06 09:09:44 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ]
    }
  ]
}