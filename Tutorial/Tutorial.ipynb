{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MengOonLee/Web_scraping/blob/master/Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./venv.sh\n",
    "pip install --no-cache-dir -U pip wheel build\n",
    "pip install --no-cache-dir -U scrapy\n",
    "pip check\n",
    "rm -rf dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile pip_install.sh\n",
    "#!/bin/bash\n",
    "pip install --no-cache-dir -U pip wheel\n",
    "pip install --no-cache-dir -U numpy pandas matplotlib seaborn\n",
    "pip install --no-cache-dir -U scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## XPaths & Selectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes\n",
    "\n",
    "`<tag attrib=\"attrib info\">...</tag>`\n",
    "  - `<div id=\"unique\" class=\"non unique\">...</div>`  \n",
    "  - `<a href=\"https://...\">...</a>`\n",
    "\n",
    "`@`: attributes\n",
    "  - `@id`, `@class`, `@href`\n",
    "  \n",
    "### XPaths notation\n",
    "\n",
    "xpath = '//*[@id=\"uid\"]/p[2]'  \n",
    "- `/`: look forward one generation  \n",
    "- `[]`: narrow on specific elements  \n",
    "- `//`: look forward all generations  \n",
    "- `*`: wildcard\n",
    "\n",
    "xpath = '//*[contains(@class, \"expr\")]'\n",
    "\n",
    "xpath = '//*/@class'\n",
    "\n",
    "XPath: `<xpath-to-element>/@attr-name`  \n",
    "xpath = '//div[@id=\"uid\"]/a/@href'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selector object\n",
    "# Import a scrapy Selector\n",
    "from scrapy import Selector\n",
    "\n",
    "# Import requests\n",
    "import requests\n",
    "url = 'https://en.wikipedia.org/wiki/Web_scraping'\n",
    "# Create the string html containing the HTML source\n",
    "html = requests.get(url).content\n",
    "\n",
    "# Create the Selector object sel from html\n",
    "sel = Selector(text=html)\n",
    "\n",
    "# Outputs the SelectorList:\n",
    "sel.xpath('//p')\n",
    "# out: [<Selector xpath='//p' data='<p>..</p>'>, ...]\n",
    "\n",
    "sel.xpath('//p').extract()\n",
    "# out: ['<p>...</p>', ...]\n",
    "\n",
    "sel.xpath('//p').extract_first()\n",
    "# out: '<p>...</p>'\n",
    "\n",
    "# Text extraction for future generations\n",
    "sel.xpath('//p[@id=\"uid\"]//text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS & Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSS Locator\n",
    "\n",
    "CSS: Cascading Style Sheets  \n",
    "`/` replaced by `>`\n",
    "- XPath: `/html/body/div`  \n",
    "- CSS: `html > body > div`\n",
    "\n",
    "`//` replaced by ` `\n",
    "- XPath: `//div/span//p`  \n",
    "- CSS: `div > span p`\n",
    "\n",
    "`[N]` replaced by `:nth-of-type(N)`\n",
    "- XPath: `//div/p[2]`  \n",
    "- CSS: `div > p:nth-of-type(2)`\n",
    "\n",
    "`<tag>.<class>`: find element by class  \n",
    "`<tag>#<id>`: find element by id\n",
    "\n",
    "CSS Locator: `<css-to-element>::attr(attr-name)`  \n",
    "css_locator = 'div#uid > a::attr(href)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy import Selector\n",
    "\n",
    "# Create a selector from the html\n",
    "sel = Selector(text=html)\n",
    "\n",
    "sel.css('div > p')\n",
    "# out: [<Selector xpath='...' data='<p>...</p>'>, ...]\n",
    "\n",
    "sel.css('div > p').extract()\n",
    "# out: [<p>...</p>, ...]\n",
    "\n",
    "# hyperlink children of all div belongs to class course-block\n",
    "sel.css('div.course-block > a')\n",
    "\n",
    "# all element's class = class-1\n",
    "sel.css('.class-1')\n",
    "\n",
    "# Create the CSS Locator to all children of the element whose id is uid\n",
    "sel.css('#uid > *')\n",
    "\n",
    "# Text extraction for future generations\n",
    "sel.css('p#uid ::text').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XPaths Notation & CSS Locators\n",
    "from scrapy import Selector\n",
    "\n",
    "# Create a selector object from a secret website\n",
    "sel = Selector(text=html)\n",
    "\n",
    "# Select all hyperlinks of div elements belonging to class \"course-block\"\n",
    "course_as = sel.css('div.course-block > a')\n",
    "\n",
    "# Selecting all href attributes chaining with css\n",
    "hrefs_from_css = course_as.css('::attr(href)')\n",
    "\n",
    "# Selecting all href attributes chaining with xpath\n",
    "hrefs_from_xpath = course_as.xpath('./@href')\n",
    "\n",
    "# Create an XPath string to the desired text.\n",
    "xpath = '//p[@id=\"p3\"]/text()'\n",
    "# Create a CSS Locator string to the desired text.\n",
    "css_locator = 'p#p3::text'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response\n",
    "\n",
    "- has all the tools with Selectors  \n",
    "- keeps track of the url  \n",
    "- move from one side to another  \n",
    "\n",
    "XPath:  \n",
    "response.xpath('//div/span[@class=\"bio\"]')  \n",
    "CSS:  \n",
    "response.css('div > span.bio')  \n",
    "Chaining:  \n",
    "response.xpath('//div').css('span.bio')  \n",
    "\n",
    "`response.url`: keeps track URL  \n",
    "`response.follow(next_url)`: follow a new link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the URL to the website loaded in response\n",
    "this_url = response.url\n",
    "\n",
    "# Get the title of the website loaded in response\n",
    "this_title = response.xpath('/html/head/title')\\\n",
    "    .css('::text').extract_first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./myspider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./myspider.py\n",
    "import scrapy\n",
    "\n",
    "class BlogSpider(scrapy.Spider):\n",
    "    name ='blogspider'\n",
    "    start_urls = ['https://www.zyte.com/blog/']\n",
    "    \n",
    "    def parse(self, response):\n",
    "        for title in response.css('.oxy-post-title'):\n",
    "            yield {'title': title.css('::text').get()}\n",
    "            \n",
    "        for next_page in response.css('a.next'):\n",
    "            yield response.follow(next_page, self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./run.sh\n",
    "#!/bin/bash\n",
    "\n",
    "scrapy runspider myspider.py -o myspider.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kDDBjF019o71",
    "outputId": "b879accb-647b-42ef-e5fb-f16c2310f99e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = 'quotes'\n",
    "    start_urls = ['https://quotes.toscrape.com/tag/humor/']\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'author': quote.xpath('span/small/text()').get(),\n",
    "                'text': quote.css('span.text::text').get()\n",
    "            }\n",
    "\n",
    "        next_page = response.css('li.next a::attr(\"href\")').get()\n",
    "        if next_page is not None:\n",
    "            yield response.follow(next_page, self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wTGIArVO9tCh",
    "outputId": "0a78d94f-3bdb-45b3-d8a5-b575bf8e484c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./run.sh\n",
    "#!/bin/bash\n",
    "\n",
    "scrapy runspider quotes_spider.py -o quotes.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9AL5k0C9wOu",
    "tags": []
   },
   "source": [
    "### Creating a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BjPrLOnu9x3G",
    "outputId": "c60a02c9-98d2-4531-a37f-6981ab18dcc5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./start_project.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./start_project.sh\n",
    "#!/bin/bash\n",
    "\n",
    "scrapy startproject tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### How to run spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhiubCScAAL6",
    "outputId": "20a90127-5f19-4d83-bf78-718be0638224"
   },
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "\n",
    "    def start_request(self):\n",
    "        urls = [\n",
    "            'https://quotes.toscrape.com/page/1/',\n",
    "            'https://quotes.toscrape.com/page/2/'\n",
    "        ]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = f'quotes-{page}.html'\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.body)\n",
    "        self.log(f'Saved file {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Ck1_F6jFD53",
    "outputId": "655e1795-902a-4246-fc43-8218aebd00d6",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Shortcut to the start_requests method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIeH3gbpFNwQ",
    "outputId": "12c4a9ef-1052-4731-8090-7d0c27c8705c"
   },
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'https://quotes.toscrape.com/page/1/',\n",
    "        'https://quotes.toscrape.com/page/2/'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = f'quotes-{page}.html'\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CK4Jqzq1RkQr",
    "outputId": "20fe2b83-70dd-431c-e9fe-f83b7933cd6b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Er9G3K7RVCwc",
    "outputId": "18047f74-436d-443e-d955-369df8c0421e",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "scrapy shell \"https://quotes.toscrape.com/page/1/\"\n",
    "response.css('title::text').getall()\n",
    "response.css('title::text').get()\n",
    "response.css('title::text').re(r'Quotes.*')\n",
    "response.css('title::text').re(r'Q\\w+')\n",
    "response.css('title::text').re(r'(\\w+) to (\\w+)')\n",
    "response.xpath('//title/text()').getall()\n",
    "response.xpath('//title/text()').get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBNvI5rsYNi5",
    "outputId": "582366eb-b4a1-4865-c106-992fc89da345",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "scrapy shell \"https://quotes.toscrape.com\"\n",
    "quote = response.css(\"div.quote\")[0]\n",
    "quote.css(\"span.text::text\").get()\n",
    "quote.css(\"small.author::text\").get()\n",
    "quote.css(\"div.tags a.tag::text\").getall()\n",
    "\n",
    "for quote in response.css(\"div.quote\"):\n",
    "    text = quote.css(\"span.text::text\").get()\n",
    "    author = quote.css(\"small.author::text\").get()\n",
    "    tags = quote.css(\"div.tags a.tag::text\").getall()\n",
    "    print(dict(text=text, author=author, tags=tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data in spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0SnvXeOJt3KK",
    "outputId": "90a06139-1b97-45a6-fefc-4a1271211cf7"
   },
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "      'https://quotes.toscrape.com/page/1/',\n",
    "      'https://quotes.toscrape.com/page/2/'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall()\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBmQ1PfP6SDC",
    "outputId": "35af10e9-bec4-4e9f-d85b-ab4f689819d5",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "roz26Udn6cDj",
    "outputId": "efd1e2ec-fdc1-43a0-f770-ba15cf448dc3",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "rm -rf tutorial/quotes.json\n",
    "scrapy crawl quotes -O quotes.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ok8vKftv7dDq",
    "outputId": "964b3726-9cf6-4ce4-c96e-51323207b78d",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "rm -rf tutorial/quotes.jl\n",
    "scrapy crawl quotes -o quotes.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "scrapy shell \"https://quotes.toscrape.com\"\n",
    "response.css(\"li.next a\").get()\n",
    "response.css(\"li.next a::attr(href)\").get()\n",
    "response.css(\"li.next a\").attrib[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "      'https://quotes.toscrape.com/page/1/'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall()\n",
    "            }\n",
    "        next_page = response.css('li.next a::attr(href)').get()\n",
    "        if next_page is not None:\n",
    "            next_page = response.urljoin(next_page)\n",
    "            yield scrapy.Request(next_page, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "rm -rf tutorial/quotes.jl\n",
    "scrapy crawl quotes -o quotes.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supports relative URLs directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'https://quotes.toscrape.com/page/1/'\n",
    "    ]\n",
    "    \n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall()\n",
    "            }\n",
    "        next_page = response.css('li.next a::attr(href)').get()\n",
    "        if next_page is not None:\n",
    "            yield response.follow(next_page, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "rm -rf tutorial/quotes.jl\n",
    "scrapy crawl quotes -o quotes.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'https://quotes.toscrape.com'\n",
    "    ]\n",
    "    \n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall()\n",
    "            }\n",
    "        for href in response.css('li.next a::attr(href)'):\n",
    "            yield response.follow(href, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "rm -rf tutorial/quotes.jl\n",
    "scrapy crawl quotes -o quotes.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'https://quotes.toscrape.com'\n",
    "    ]\n",
    "    \n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall()\n",
    "            }\n",
    "        for a in response.css('ul.pager li.next a'):\n",
    "            yield response.follow(a, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "rm -rf tutorial/quotes.jl\n",
    "scrapy crawl quotes -o quotes.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create multiple requests from an iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'https://quotes.toscrape.com'\n",
    "    ]\n",
    "    \n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall()\n",
    "            }\n",
    "        anchors = response.css('ul.pager li.next a')\n",
    "        yield from response.follow_all(anchors, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "rm -rf tutorial/quotes.jl\n",
    "scrapy crawl quotes -o quotes.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'https://quotes.toscrape.com'\n",
    "    ]\n",
    "    \n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall()\n",
    "            }\n",
    "        yield from response.follow_all(css='ul.pager li.next a', callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "rm -rf tutorial/quotes.jl\n",
    "scrapy crawl quotes -o quotes.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/author_spider.py\n",
    "import scrapy\n",
    "\n",
    "class AuthorSpider(scrapy.Spider):\n",
    "    name = 'author'\n",
    "    \n",
    "    start_urls = ['https://quotes.toscrape.com/']\n",
    "    \n",
    "    def parse(self, response):\n",
    "        author_page_links = response.css('.author + a')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOJeDMq173KlrdlGG8ohN66",
   "include_colab_link": true,
   "name": "Tutorial",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
