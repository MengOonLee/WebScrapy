{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/Web_scraping/blob/master/Tutorial/Scrapy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvXGXei0CJFI"
      },
      "source": [
        "# Scrapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vi9PaP1PCJFN"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "pip install --no-cache-dir -qU scrapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUWOvXRPCJFT",
        "outputId": "bbd7102d-66fb-43b1-cfd0-e00574a76ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Jane Austen\n",
            "Text: “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
            "Next page: /tag/humor/page/2/\n"
          ]
        }
      ],
      "source": [
        "import scrapy\n",
        "import requests\n",
        "url = \"https://quotes.toscrape.com/tag/humor/\"\n",
        "html = requests.get(url).content\n",
        "\n",
        "sel = scrapy.Selector(text=html)\n",
        "quote = sel.css('div.quote')\n",
        "author = quote.css('small.author::text').get()\n",
        "print('Author:', author)\n",
        "text = quote.css('span.text::text').get()\n",
        "print('Text:', text)\n",
        "\n",
        "next_page = sel.css('li.next a::attr(href)').get()\n",
        "print('Next page:', next_page)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lEgazWXOCJFQ",
        "outputId": "2683890a-032c-4068-cae9-0398a2745daa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Scrapy project 'Tutorial', using template directory '/usr/local/lib/python3.10/dist-packages/scrapy/templates/project', created in:\n",
            "    /content/Tutorial\n",
            "\n",
            "You can start your first spider with:\n",
            "    cd Tutorial\n",
            "    scrapy genspider example example.com\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "rm -rf Tutorial\n",
        "scrapy startproject Tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN4jZIGICJFV",
        "outputId": "a9da73a1-4f78-4449-836f-f7e1408c0d6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ./ScrapyTutorial/myspider.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./Tutorial/spider.py\n",
        "import scrapy\n",
        "\n",
        "class BlogSpider(scrapy.Spider):\n",
        "    name ='blogspider'\n",
        "    start_urls = [\"https://www.zyte.com/blog/\"]\n",
        "\n",
        "    def parse(self, response):\n",
        "        for title in response.css('.oxy-post-title'):\n",
        "            yield {'title': title.css('::text').get()}\n",
        "\n",
        "        for next_page in response.css('a.next'):\n",
        "            yield response.follow(next_page, self.parse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lYj3sx7CJFY",
        "outputId": "fc28524c-96e9-480f-9aab-eede01ad8986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-09 13:12:00 [scrapy.utils.log] INFO: Scrapy 2.10.1 started (bot: scrapybot)\n",
            "2023-09-09 13:12:00 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0], pyOpenSSL 23.2.0 (OpenSSL 3.1.2 1 Aug 2023), cryptography 41.0.3, Platform Linux-5.15.109+-x86_64-with-glibc2.35\n",
            "2023-09-09 13:12:00 [scrapy.addons] INFO: Enabled addons:\n",
            "[]\n",
            "2023-09-09 13:12:00 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'SPIDER_LOADER_WARN_ONLY': True}\n",
            "/usr/local/lib/python3.10/dist-packages/scrapy/utils/request.py:248: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
            "\n",
            "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
            "\n",
            "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
            "  return cls(crawler)\n",
            "2023-09-09 13:12:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2023-09-09 13:12:01 [scrapy.extensions.telnet] INFO: Telnet Password: ef8cb53d6da76557\n",
            "2023-09-09 13:12:01 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2023-09-09 13:12:01 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2023-09-09 13:12:01 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2023-09-09 13:12:01 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2023-09-09 13:12:01 [scrapy.core.engine] INFO: Spider opened\n",
            "2023-09-09 13:12:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2023-09-09 13:12:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2023-09-09 13:12:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.zyte.com/blog/> (referer: None)\n",
            "2023-09-09 13:12:02 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2023-09-09 13:12:02 [scrapy.extensions.feedexport] INFO: Stored jl feed (0 items) in: ./data/myspider.jl\n",
            "2023-09-09 13:12:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 218,\n",
            " 'downloader/request_count': 1,\n",
            " 'downloader/request_method_count/GET': 1,\n",
            " 'downloader/response_bytes': 119302,\n",
            " 'downloader/response_count': 1,\n",
            " 'downloader/response_status_count/200': 1,\n",
            " 'elapsed_time_seconds': 0.826608,\n",
            " 'feedexport/success_count/FileFeedStorage': 1,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2023, 9, 9, 13, 12, 2, 11682),\n",
            " 'httpcompression/response_bytes': 782614,\n",
            " 'httpcompression/response_count': 1,\n",
            " 'log_count/DEBUG': 2,\n",
            " 'log_count/INFO': 11,\n",
            " 'memusage/max': 69996544,\n",
            " 'memusage/startup': 69996544,\n",
            " 'response_received_count': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2023, 9, 9, 13, 12, 1, 185074)}\n",
            "2023-09-09 13:12:02 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "scrapy runspider ./ScrapyTutorial/myspider.py -O ./data/myspider.jl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "s8ecmnZXCJFZ",
        "outputId": "cab42b68-30f6-48a4-ee90-c5c95d328b0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 00:10:27 [scrapy.utils.log] INFO: Scrapy 2.10.1 started (bot: scrapybot)\n",
            "2023-09-09 00:10:27 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.8.10 (default, Mar 13 2023, 10:26:41) - [GCC 9.4.0], pyOpenSSL 23.2.0 (OpenSSL 3.1.2 1 Aug 2023), cryptography 41.0.3, Platform Linux-6.2.0-31-generic-x86_64-with-glibc2.29\n",
            "2023-09-09 00:10:27 [scrapy.addons] INFO: Enabled addons:\n",
            "[]\n",
            "2023-09-09 00:10:27 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'SPIDER_LOADER_WARN_ONLY': True}\n",
            "2023-09-09 00:10:27 [py.warnings] WARNING: /Work/venv/lib/python3.8/site-packages/scrapy/utils/request.py:248: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
            "\n",
            "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
            "\n",
            "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
            "  return cls(crawler)\n",
            "\n",
            "2023-09-09 00:10:27 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2023-09-09 00:10:27 [scrapy.extensions.telnet] INFO: Telnet Password: 7c25b7c4780f6c97\n",
            "2023-09-09 00:10:27 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2023-09-09 00:10:27 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2023-09-09 00:10:27 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2023-09-09 00:10:27 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2023-09-09 00:10:27 [scrapy.core.engine] INFO: Spider opened\n",
            "2023-09-09 00:10:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2023-09-09 00:10:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2023-09-09 00:10:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.zyte.com/blog/> (referer: None)\n",
            "2023-09-09 00:10:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2023-09-09 00:10:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 224,\n",
            " 'downloader/request_count': 1,\n",
            " 'downloader/request_method_count/GET': 1,\n",
            " 'downloader/response_bytes': 119302,\n",
            " 'downloader/response_count': 1,\n",
            " 'downloader/response_status_count/200': 1,\n",
            " 'elapsed_time_seconds': 0.792555,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2023, 9, 9, 0, 10, 28, 173801),\n",
            " 'httpcompression/response_bytes': 782614,\n",
            " 'httpcompression/response_count': 1,\n",
            " 'log_count/DEBUG': 2,\n",
            " 'log_count/INFO': 10,\n",
            " 'log_count/WARNING': 1,\n",
            " 'memusage/max': 57614336,\n",
            " 'memusage/startup': 57614336,\n",
            " 'response_received_count': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2023, 9, 9, 0, 10, 27, 381246)}\n",
            "2023-09-09 00:10:28 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "scrapy runspider ./ScrapyTutorial/myspider.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCvzb4pLCJFZ"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd ./ScrapyTutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "O2jqZhMsCJFb",
        "outputId": "22b501e6-36b6-4c2f-ea5f-516399639ece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "next page: ['/tag/humor/page/2/']\n",
            "author: ['Jane Austen', 'Steve Martin', 'Garrison Keillor', 'Jim Henson', 'Charles M. Schulz', 'Suzanne Collins', 'Charles Bukowski', 'Terry Pratchett', 'Dr. Seuss', 'George Carlin']\n",
            "text: ['“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', '“A day without sunshine is like, you know, night.”', '“Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.”', '“Beauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.”', \"“All you need is love. But a little chocolate now and then doesn't hurt.”\", \"“Remember, we're madly in love, so it's all right to kiss me anytime you feel like it.”\", '“Some people never go crazy. What truly horrible lives they must lead.”', '“The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.”', '“Think left and think right and think low and think high. Oh, the thinks you can think up if only you try!”', '“The reason I talk to myself is because I’m the only one whose answers I accept.”']\n"
          ]
        }
      ],
      "source": [
        "from scrapy import Selector\n",
        "import requests\n",
        "url = \"https://quotes.toscrape.com/tag/humor/\"\n",
        "html = requests.get(url).content\n",
        "\n",
        "sel = Selector(text=html)\n",
        "next_page = sel.css('li.next a::attr(\"href\")').extract()\n",
        "print(f\"next page: {next_page}\")\n",
        "\n",
        "quote = sel.css('div.quote')\n",
        "author = quote.xpath('span/small/text()').extract()\n",
        "print(f\"author: {author}\")\n",
        "text = quote.css('span.text::text').extract()\n",
        "print(f\"text: {text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDDBjF019o71",
        "outputId": "b879accb-647b-42ef-e5fb-f16c2310f99e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing ./Tutorial/quotes_spider.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./Tutorial/quotes_spider.py\n",
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = 'quotes'\n",
        "    start_urls = [\n",
        "        \"https://quotes.toscrape.com/tag/humor/\"\n",
        "    ]\n",
        "\n",
        "    def parse(self, response):\n",
        "        for quote in response.css('div.quote'):\n",
        "            yield {\n",
        "                'author': quote.xpath('span/small/text()').get(),\n",
        "                'text': quote.css('span.text::text').get()\n",
        "            }\n",
        "\n",
        "        next_page = response.css('li.next a::attr(\"href\")').get()\n",
        "        if next_page is not None:\n",
        "            yield response.follow(next_page, self.parse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTGIArVO9tCh",
        "outputId": "0a78d94f-3bdb-45b3-d8a5-b575bf8e484c",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./Tutorial/run.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./Tutorial/run.sh\n",
        "#!/bin/bash\n",
        "\n",
        "scrapy runspider quotes_spider.py -O ./data/quotes.jl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIeH3gbpFNwQ",
        "outputId": "12c4a9ef-1052-4731-8090-7d0c27c8705c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./Tutorial/Tutorial/spiders/quotes_spider.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./Tutorial/Tutorial/spiders/quotes_spider.py\n",
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = \"quotes\"\n",
        "    start_urls = [\n",
        "        \"https://quotes.toscrape.com/page/1/\",\n",
        "        \"https://quotes.toscrape.com/page/2/\"\n",
        "    ]\n",
        "\n",
        "    def parse(self, response):\n",
        "        page = response.url.split(\"/\")[-2]\n",
        "        filename = f'./data/quotes-{page}.html'\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(response.body)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ck1_F6jFD53",
        "outputId": "655e1795-902a-4246-fc43-8218aebd00d6",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./Tutorial/run.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./Tutorial/run.sh\n",
        "#!/bin/bash\n",
        "\n",
        "scrapy crawl quotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqcv_k7tCJFn",
        "outputId": "a8362a3d-e257-4fce-f39e-f2e69678eb3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "css title: [<Selector xpath='descendant-or-self::title/text()' data='Quotes to Scrape'>]\n",
            "['Quotes', 'Scrape']\n",
            "xpath title: [<Selector xpath='//title/text()' data='Quotes to Scrape'>]\n"
          ]
        }
      ],
      "source": [
        "from scrapy import Selector\n",
        "import requests\n",
        "\n",
        "url = \"https://quotes.toscrape.com/page/1/\"\n",
        "html = requests.get(url).content\n",
        "\n",
        "sel = Selector(text=html)\n",
        "# CSS\n",
        "title = sel.css('title::text')\n",
        "print(f\"css title: {title}\")\n",
        "print(title.re(r'(\\w+) to (\\w+)'))\n",
        "\n",
        "# XPath\n",
        "title = sel.xpath('//title/text()')\n",
        "print(f\"xpath title: {title}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true,
        "tags": [],
        "id": "E2o-JD25CJFp",
        "outputId": "3df0327a-9d9d-4fb6-e168-b63d7f1e2517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}\n",
            "{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}\n",
            "{'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein', 'tags': ['inspirational', 'life', 'live', 'miracle', 'miracles']}\n",
            "{'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'author': 'Jane Austen', 'tags': ['aliteracy', 'books', 'classic', 'humor']}\n",
            "{'text': \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'author': 'Marilyn Monroe', 'tags': ['be-yourself', 'inspirational']}\n",
            "{'text': '“Try not to become a man of success. Rather become a man of value.”', 'author': 'Albert Einstein', 'tags': ['adulthood', 'success', 'value']}\n",
            "{'text': '“It is better to be hated for what you are than to be loved for what you are not.”', 'author': 'André Gide', 'tags': ['life', 'love']}\n",
            "{'text': \"“I have not failed. I've just found 10,000 ways that won't work.”\", 'author': 'Thomas A. Edison', 'tags': ['edison', 'failure', 'inspirational', 'paraphrased']}\n",
            "{'text': \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", 'author': 'Eleanor Roosevelt', 'tags': ['misattributed-eleanor-roosevelt']}\n",
            "{'text': '“A day without sunshine is like, you know, night.”', 'author': 'Steve Martin', 'tags': ['humor', 'obvious', 'simile']}\n"
          ]
        }
      ],
      "source": [
        "from scrapy import Selector\n",
        "import requests\n",
        "\n",
        "url = \"https://quotes.toscrape.com/\"\n",
        "html = requests.get(url).content\n",
        "\n",
        "sel = Selector(text=html)\n",
        "\n",
        "for quote in sel.css('div.quote'):\n",
        "    text = quote.css('span.text::text').extract_first()\n",
        "    author = quote.css('small.author::text').extract_first()\n",
        "    tags = quote.css('div.tags a.tag::text').extract()\n",
        "    print(dict(text=text, author=author, tags=tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SnvXeOJt3KK",
        "outputId": "90a06139-1b97-45a6-fefc-4a1271211cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./Tutorial/Tutorial/spiders/quotes_spider.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./Tutorial/Tutorial/spiders/quotes_spider.py\n",
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = \"quotes\"\n",
        "    start_urls = [\n",
        "      'https://quotes.toscrape.com/page/1/',\n",
        "      'https://quotes.toscrape.com/page/2/'\n",
        "    ]\n",
        "\n",
        "    def parse(self, response):\n",
        "        for quote in response.css('div.quote'):\n",
        "            yield {\n",
        "                'text': quote.css('span.text::text').get(),\n",
        "                'author': quote.css('small.author::text').get(),\n",
        "                'tags': quote.css('div.tags a.tag::text').getall()\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBmQ1PfP6SDC",
        "outputId": "35af10e9-bec4-4e9f-d85b-ab4f689819d5",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./Tutorial/run.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./Tutorial/run.sh\n",
        "#!/bin/bash\n",
        "\n",
        "scrapy crawl quotes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aFigT5eCJFr"
      },
      "source": [
        "### Storing the scraped data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roz26Udn6cDj",
        "outputId": "efd1e2ec-fdc1-43a0-f770-ba15cf448dc3",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./Tutorial/run.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./Tutorial/run.sh\n",
        "#!/bin/bash\n",
        "\n",
        "scrapy crawl quotes -O ./data/quotes.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok8vKftv7dDq",
        "outputId": "964b3726-9cf6-4ce4-c96e-51323207b78d",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./Tutorial/run.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./Tutorial/run.sh\n",
        "#!/bin/bash\n",
        "\n",
        "scrapy crawl quotes -o ./data/quotes.jl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzp4uildCJFv"
      },
      "source": [
        "## Following links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "tzhbQfBkCJFw"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "scrapy shell \"https://quotes.toscrape.com\"\n",
        "response.css(\"li.next a\").get()\n",
        "response.css(\"li.next a::attr(href)\").get()\n",
        "response.css(\"li.next a\").attrib[\"href\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gJ_J7N1CJFw"
      },
      "outputs": [],
      "source": [
        "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = \"quotes\"\n",
        "    start_urls = [\n",
        "      'https://quotes.toscrape.com/page/1/'\n",
        "    ]\n",
        "\n",
        "    def parse(self, response):\n",
        "        for quote in response.css('div.quote'):\n",
        "            yield {\n",
        "                'text': quote.css('span.text::text').get(),\n",
        "                'author': quote.css('small.author::text').get(),\n",
        "                'tags': quote.css('div.tags a.tag::text').getall()\n",
        "            }\n",
        "        next_page = response.css('li.next a::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "acmICjxSCJFx"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd tutorial\n",
        "rm -rf tutorial/quotes.jl\n",
        "scrapy crawl quotes -o quotes.jl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Moiw3bkNCJFy"
      },
      "source": [
        "### Supports relative URLs directly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSrsFY4pCJFz"
      },
      "outputs": [],
      "source": [
        "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = \"quotes\"\n",
        "    start_urls = [\n",
        "        'https://quotes.toscrape.com/page/1/'\n",
        "    ]\n",
        "\n",
        "    def parse(self, response):\n",
        "        for quote in response.css('div.quote'):\n",
        "            yield {\n",
        "                'text': quote.css('span.text::text').get(),\n",
        "                'author': quote.css('small.author::text').get(),\n",
        "                'tags': quote.css('div.tags a.tag::text').getall()\n",
        "            }\n",
        "        next_page = response.css('li.next a::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            yield response.follow(next_page, callback=self.parse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "66jeaDK8CJFz"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd tutorial\n",
        "rm -rf tutorial/quotes.jl\n",
        "scrapy crawl quotes -o quotes.jl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXeh8nZ2CJF0"
      },
      "outputs": [],
      "source": [
        "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = \"quotes\"\n",
        "    start_urls = [\n",
        "        'https://quotes.toscrape.com'\n",
        "    ]\n",
        "\n",
        "    def parse(self, response):\n",
        "        for quote in response.css('div.quote'):\n",
        "            yield {\n",
        "                'text': quote.css('span.text::text').get(),\n",
        "                'author': quote.css('small.author::text').get(),\n",
        "                'tags': quote.css('div.tags a.tag::text').getall()\n",
        "            }\n",
        "        for href in response.css('li.next a::attr(href)'):\n",
        "            yield response.follow(href, callback=self.parse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "zz8tx-EqCJF0"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd tutorial\n",
        "rm -rf tutorial/quotes.jl\n",
        "scrapy crawl quotes -o quotes.jl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQB5CAhDCJF1"
      },
      "outputs": [],
      "source": [
        "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = \"quotes\"\n",
        "    start_urls = [\n",
        "        'https://quotes.toscrape.com'\n",
        "    ]\n",
        "\n",
        "    def parse(self, response):\n",
        "        for quote in response.css('div.quote'):\n",
        "            yield {\n",
        "                'text': quote.css('span.text::text').get(),\n",
        "                'author': quote.css('small.author::text').get(),\n",
        "                'tags': quote.css('div.tags a.tag::text').getall()\n",
        "            }\n",
        "        for a in response.css('ul.pager li.next a'):\n",
        "            yield response.follow(a, callback=self.parse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "eKjNALacCJF1"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd tutorial\n",
        "rm -rf tutorial/quotes.jl\n",
        "scrapy crawl quotes -o quotes.jl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9kHIFzPCJF2"
      },
      "source": [
        "### Create multiple requests from an iterable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6dqwRX-CJF3"
      },
      "outputs": [],
      "source": [
        "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = \"quotes\"\n",
        "    start_urls = [\n",
        "        'https://quotes.toscrape.com'\n",
        "    ]\n",
        "\n",
        "    def parse(self, response):\n",
        "        for quote in response.css('div.quote'):\n",
        "            yield {\n",
        "                'text': quote.css('span.text::text').get(),\n",
        "                'author': quote.css('small.author::text').get(),\n",
        "                'tags': quote.css('div.tags a.tag::text').getall()\n",
        "            }\n",
        "        anchors = response.css('ul.pager li.next a')\n",
        "        yield from response.follow_all(anchors, callback=self.parse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "EBY4_jlgCJF4"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd tutorial\n",
        "rm -rf tutorial/quotes.jl\n",
        "scrapy crawl quotes -o quotes.jl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCTtEFJ4CJF5"
      },
      "outputs": [],
      "source": [
        "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = \"quotes\"\n",
        "    start_urls = [\n",
        "        'https://quotes.toscrape.com'\n",
        "    ]\n",
        "\n",
        "    def parse(self, response):\n",
        "        for quote in response.css('div.quote'):\n",
        "            yield {\n",
        "                'text': quote.css('span.text::text').get(),\n",
        "                'author': quote.css('small.author::text').get(),\n",
        "                'tags': quote.css('div.tags a.tag::text').getall()\n",
        "            }\n",
        "        yield from response.follow_all(css='ul.pager li.next a', callback=self.parse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "eTDBh7ZFCJF5"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd tutorial\n",
        "rm -rf tutorial/quotes.jl\n",
        "scrapy crawl quotes -o quotes.jl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1_jnBpXCJF5"
      },
      "source": [
        "## More patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3ChZ_6SCJF5"
      },
      "outputs": [],
      "source": [
        "%%writefile ./tutorial/tutorial/spiders/author_spider.py\n",
        "import scrapy\n",
        "\n",
        "class AuthorSpider(scrapy.Spider):\n",
        "    name = 'author'\n",
        "\n",
        "    start_urls = ['https://quotes.toscrape.com/']\n",
        "\n",
        "    def parse(self, response):\n",
        "        author_page_links = response.css('.author + a')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Scrapy",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}