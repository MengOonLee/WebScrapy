{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MengOonLee/Web_scraping/blob/master/Tutorial/Scrapy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvXGXei0CJFI"
   },
   "source": [
    "# Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vi9PaP1PCJFN"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip install --no-cache-dir -qU scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUWOvXRPCJFT",
    "outputId": "bbd7102d-66fb-43b1-cfd0-e00574a76ce2",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import requests\n",
    "\n",
    "url = \"https://quotes.toscrape.com/tag/humor/\"\n",
    "html = requests.get(url).content\n",
    "\n",
    "sel = scrapy.Selector(text=html)\n",
    "quote = sel.css(\"div.quote\")\n",
    "author = quote.xpath(\"span/small/text()\").get()\n",
    "print(\"Author:\", author)\n",
    "text = quote.css(\"span.text::text\").get()\n",
    "print(\"Text:\", text)\n",
    "next_page = sel.css(\"li.next a::attr(href)\").get()\n",
    "print(\"Next page:\", next_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.loader import ItemLoader\n",
    "from itemloaders.processors import MapCompose, TakeFirst\n",
    "from w3lib.html import remove_tags\n",
    "import re\n",
    "\n",
    "def remove_unicode(text):\n",
    "    return text.encode('ascii', errors='ignore')\\\n",
    "        .decode().strip()\n",
    "\n",
    "class QuotesItem(scrapy.Item):\n",
    "    author = scrapy.Field(\n",
    "        input_processor=MapCompose(remove_tags),\n",
    "        output_processor=TakeFirst()\n",
    "    )\n",
    "    text = scrapy.Field(\n",
    "        input_processor=MapCompose(remove_tags, remove_unicode),\n",
    "        output_processor=TakeFirst()\n",
    "    )\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/tag/humor/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            l = ItemLoader(item=QuotesItem(), selector=quote)\n",
    "            l.add_xpath(\"author\", \"span/small/text()\")\n",
    "            l.add_css(\"text\", \"span.text::text\")\n",
    "            yield l.load_item()\n",
    "\n",
    "        next_page = response.css(\"li.next a::attr(href)\").get()\n",
    "        if next_page is not None:\n",
    "            yield response.follow(next_page, self.parse)\n",
    "\n",
    "process = CrawlerProcess(\n",
    "    settings={\n",
    "        \"FEEDS\":{\"items.jl\":{\"format\":\"jsonlines\"}}\n",
    "    }\n",
    ")\n",
    "process.crawl(QuotesSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIeH3gbpFNwQ",
    "outputId": "12c4a9ef-1052-4731-8090-7d0c27c8705c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import pathlib\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = [\n",
    "            \"https://quotes.toscrape.com/page/1/\",\n",
    "            \"https://quotes.toscrape.com/page/2/\"\n",
    "        ]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = f\"quotes-{page}.html\"\n",
    "        pathlib.Path(filename).write_bytes(response.body)\n",
    "        self.log(f\"Saved file {filename}\")\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(QuotesSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import pathlib\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\",\n",
    "        \"https://quotes.toscrape.com/page/2/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = f\"quotes-{page}.html\"\n",
    "        pathlib.Path(filename).write_bytes(response.body)\n",
    "        self.log(f\"Saved file {filename}\")\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(QuotesSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import requests\n",
    "\n",
    "url = \"https://quotes.toscrape.com/page/1/\"\n",
    "html = requests.get(url).content\n",
    "\n",
    "sel = scrapy.Selector(text=html)\n",
    "\n",
    "print(sel.css(\"title\"))\n",
    "print(sel.css(\"title::text\").get())\n",
    "print(sel.css(\"title::text\").re(r\"Quotes.*\"))\n",
    "print(sel.css(\"title::text\").re(r\"Q\\w+\"))\n",
    "print(sel.css(\"title::text\").re(r\"(\\w+) to (\\w+)\"))\n",
    "\n",
    "print(sel.xpath(\"//title\"))\n",
    "print(sel.xpath(\"//title/text()\").get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import requests\n",
    "\n",
    "url = \"https://quotes.toscrape.com/page/1/\"\n",
    "html = requests.get(url).content\n",
    "\n",
    "sel = scrapy.Selector(text=html)\n",
    "\n",
    "quote = sel.css(\"div.quote\")[0]\n",
    "print(quote)\n",
    "text = quote.css(\"span.text::text\").get()\n",
    "print(text)\n",
    "author = quote.css(\"small.author::text\").get()\n",
    "print(author)\n",
    "tags = quote.css(\"div.tags a.tag::text\").getall()\n",
    "print(tags)\n",
    "\n",
    "for quote in sel.css(\"div.quote\"):\n",
    "    text = quote.css(\"span.text::text\").get()\n",
    "    author = quote.css(\"small.author::text\").get()\n",
    "    tags = quote.css(\"div.tags a.tag::text\").getall()\n",
    "    print(dict(text=text, author=author, tags=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.loader import ItemLoader\n",
    "from itemloaders.processors import MapCompose, TakeFirst, Identity\n",
    "from w3lib.html import remove_tags\n",
    "import re\n",
    "\n",
    "def remove_unicode(text):\n",
    "    return text.encode(\"ascii\", errors=\"ignore\").decode().strip()\n",
    "\n",
    "class QuotesItem(scrapy.Item):\n",
    "    author = scrapy.Field(\n",
    "        input_processor=MapCompose(remove_tags, remove_unicode),\n",
    "        output_processor=TakeFirst()\n",
    "    )\n",
    "    text = scrapy.Field(\n",
    "        input_processor=MapCompose(remove_tags, remove_unicode),\n",
    "        output_processor=TakeFirst()\n",
    "    )\n",
    "    tags = scrapy.Field(\n",
    "        input_processor=MapCompose(remove_tags),\n",
    "        output_processor=Identity()\n",
    "    )\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\",\n",
    "        \"https://quotes.toscrape.com/page/2/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            l = ItemLoader(item=QuotesItem(), selector=quote)\n",
    "            l.add_css(\"author\", \"small.author::text\")\n",
    "            l.add_css(\"text\", \"span.text::text\")\n",
    "            l.add_css(\"tags\", \"div.tags a.tag::text\")\n",
    "            yield l.load_item()\n",
    "\n",
    "process = CrawlerProcess(\n",
    "    settings={\n",
    "        \"FEEDS\":{\"items.jl\":{\"format\":\"jsonlines\"}}\n",
    "    }\n",
    ")\n",
    "process.crawl(QuotesSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import requests\n",
    "\n",
    "url = \"https://quotes.toscrape.com/page/1\"\n",
    "html = requests.get(url).content\n",
    "\n",
    "sel = scrapy.Selector(text=html)\n",
    "next = sel.css(\"li.next a::attr(href)\").get()\n",
    "print(next)\n",
    "next = sel.css(\"li.next a\").attrib[\"href\"]\n",
    "print(next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.loader import ItemLoader\n",
    "from itemloaders.processors import MapCompose, TakeFirst, Identity\n",
    "from w3lib.html import remove_tags\n",
    "import re\n",
    "\n",
    "def remove_unicode(text):\n",
    "    return text.encode(\"ascii\", errors=\"ignore\").decode().strip()\n",
    "\n",
    "class QuotesItem(scrapy.Item):\n",
    "    author = scrapy.Field(\n",
    "        input_processor=MapCompose(remove_tags, remove_unicode),\n",
    "        output_processor=TakeFirst()\n",
    "    )\n",
    "    text = scrapy.Field(\n",
    "        input_processor=MapCompose(remove_tags, remove_unicode),\n",
    "        output_processor=TakeFirst()\n",
    "    )\n",
    "    tags = scrapy.Field(\n",
    "        input_processor=MapCompose(remove_tags),\n",
    "        output_processor=Identity()\n",
    "    )\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            l = ItemLoader(item=QuotesItem(), selector=quote)\n",
    "            l.add_css(\"author\", \"small.author::text\")\n",
    "            l.add_css(\"text\", \"span.text::text\")\n",
    "            l.add_css(\"tags\", \"div.tags a.tag::text\")\n",
    "            yield l.load_item()\n",
    "\n",
    "        next_page = response.css(\"li.next a::attr(href)\").get()\n",
    "        if next_page is not None:\n",
    "            next_page = response.urljoin(next_page)\n",
    "            yield scrapy.Request(next_page, callback=self.parse)\n",
    "\n",
    "process = CrawlerProcess(\n",
    "    settings={\n",
    "        \"FEEDS\":{\"items.jl\":{\"format\":\"jsonlines\"}}\n",
    "    }\n",
    ")\n",
    "process.crawl(QuotesSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"text\": quote.css(\"span.text::text\").get(),\n",
    "                \"author\": quote.css(\"span small::text\").get(),\n",
    "                \"tags\": quote.css(\"div.tags a.tag::text\").getall()\n",
    "            }\n",
    "\n",
    "        next_page = response.css(\"li.next a::attr(href)\").get()\n",
    "        if next_page is not None:\n",
    "            yield response.follow(next_page, callback=self.parse)\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(QuotesSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"text\": quote.css(\"span.text::text\").get(),\n",
    "                \"author\": quote.css(\"span small::text\").get(),\n",
    "                \"tags\": quote.css(\"div.tags a.tag::text\").getall()\n",
    "            }\n",
    "\n",
    "        for href in response.css(\"ul.pager a::attr(href)\"):\n",
    "            yield response.follow(href, callback=self.parse)\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(QuotesSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"text\": quote.css(\"span.text::text\").get(),\n",
    "                \"author\": quote.css(\"span small::text\").get(),\n",
    "                \"tags\": quote.css(\"div.tags a.tag::text\").getall()\n",
    "            }\n",
    "\n",
    "        for a in response.css(\"ul.pager a\"):\n",
    "            yield response.follow(a, callback=self.parse)\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(QuotesSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"text\": quote.css(\"span.text::text\").get(),\n",
    "                \"author\": quote.css(\"span small::text\").get(),\n",
    "                \"tags\": quote.css(\"div.tags a.tag::text\").getall()\n",
    "            }\n",
    "\n",
    "        yield from response.follow_all(css=\"ul.pager a\", callback=self.parse)\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(QuotesSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class AuthorSpider(scrapy.Spider):\n",
    "    name = \"author\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        author_page_links = response.css(\".author + a\")\n",
    "        yield from response.follow_all(author_page_links, callback=self.parse_author)\n",
    "\n",
    "        pagination_links = response.css(\"li.next a\")\n",
    "        yield from response.follow_all(pagination_links, callback=self.parse)\n",
    "\n",
    "    def parse_author(self, response):\n",
    "        def extract_with_css(query):\n",
    "            return response.css(query).get(default=\"\").strip()\n",
    "\n",
    "        yield {\n",
    "            \"name\": extract_with_css(\"h3.author-title::text\"),\n",
    "            \"birthdate\": extract_with_css(\".author-born-date::text\"),\n",
    "            \"bio\": extract_with_css(\".author-description::text\")\n",
    "        }\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(AuthorSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        url = \"https://quotes.toscrape.com/\"\n",
    "        tag = getattr(self, \"tag\", None)\n",
    "        if tag is not None:\n",
    "            url = url + \"tag/\" + tag\n",
    "        yield scrapy.Request(url, self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"text\": quote.css(\"span.text::text\").get(),\n",
    "                \"author\": quote.css(\"small.author::text\").get()\n",
    "            }\n",
    "\n",
    "        next_page = response.css(\"li.next a::attr(href)\").get()\n",
    "        if next_page is not None:\n",
    "            yield response.follow(next_page, self.parse)\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(QuotesSpider, tag='humor')\n",
    "process.start()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Scrapy",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
