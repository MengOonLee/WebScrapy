{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MengOonLee/Web_scraping/blob/master/Tutorial/Scrapy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvXGXei0CJFI"
   },
   "source": [
    "# Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vi9PaP1PCJFN"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip install --no-cache-dir -qU scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUWOvXRPCJFT",
    "outputId": "bbd7102d-66fb-43b1-cfd0-e00574a76ce2",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Jane Austen\n",
      "Text: “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "Next page: /tag/humor/page/2/\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "import requests\n",
    "\n",
    "url = \"https://quotes.toscrape.com/tag/humor/\"\n",
    "html = requests.get(url).content\n",
    "\n",
    "sel = scrapy.Selector(text=html)\n",
    "quote = sel.css(\"div.quote\")\n",
    "author = quote.xpath(\"span/small/text()\").get()\n",
    "print(\"Author:\", author)\n",
    "text = quote.css(\"span.text::text\").get()\n",
    "print(\"Text:\", text)\n",
    "next_page = sel.css(\"li.next a::attr(href)\").get()\n",
    "print(\"Next page:\", next_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lEgazWXOCJFQ",
    "outputId": "2683890a-032c-4068-cae9-0398a2745daa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'tutorial', using template directory '/Work/venv/lib/python3.8/site-packages/scrapy/templates/project', created in:\n",
      "    /Work/Web_scraping/Tutorial/tutorial\n",
      "\n",
      "You can start your first spider with:\n",
      "    cd tutorial\n",
      "    scrapy genspider example example.com\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "rm -rf tutorial\n",
    "scrapy startproject tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AN4jZIGICJFV",
    "outputId": "a9da73a1-4f78-4449-836f-f7e1408c0d6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./tutorial/quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tutorial/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/tag/humor/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"author\": quote.xpath(\"span/small/text()\").get(),\n",
    "                \"text\": quote.css(\"span.text::text\").get()\n",
    "            }\n",
    "\n",
    "        next_page = response.css(\"li.next a::attr(href)\").get()\n",
    "        if next_page is not None:\n",
    "            yield response.follow(next_page, self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lYj3sx7CJFY",
    "outputId": "fc28524c-96e9-480f-9aab-eede01ad8986",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "scrapy runspider ./tutorial/quotes_spider.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIeH3gbpFNwQ",
    "outputId": "12c4a9ef-1052-4731-8090-7d0c27c8705c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./tutorial/tutorial/spiders/quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "import pathlib\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = [\n",
    "            \"https://quotes.toscrape.com/page/1/\",\n",
    "            \"https://quotes.toscrape.com/page/2/\"\n",
    "        ]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = f\"quotes-{page}.html\"\n",
    "        pathlib.Path(filename).write_bytes(response.body)\n",
    "        self.log(f\"Saved file {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Ck1_F6jFD53",
    "outputId": "655e1795-902a-4246-fc43-8218aebd00d6",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ./tutorial\n",
    "scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./tutorial/tutorial/spiders/quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "import pathlib\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\",\n",
    "        \"https://quotes.toscrape.com/page/2/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = f\"quotes-{page}.html\"\n",
    "        pathlib.Path(filename).write_bytes(response.body)\n",
    "        self.log(f\"Saved file {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ./tutorial\n",
    "scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Selector query='descendant-or-self::title' data='<title>Quotes to Scrape</title>'>]\n",
      "Quotes to Scrape\n",
      "['Quotes to Scrape']\n",
      "['Quotes']\n",
      "['Quotes', 'Scrape']\n",
      "[<Selector query='//title' data='<title>Quotes to Scrape</title>'>]\n",
      "Quotes to Scrape\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "import requests\n",
    "\n",
    "url = \"https://quotes.toscrape.com/page/1/\"\n",
    "html = requests.get(url).content\n",
    "\n",
    "sel = scrapy.Selector(text=html)\n",
    "\n",
    "print(sel.css(\"title\"))\n",
    "print(sel.css(\"title::text\").get())\n",
    "print(sel.css(\"title::text\").re(r\"Quotes.*\"))\n",
    "print(sel.css(\"title::text\").re(r\"Q\\w+\"))\n",
    "print(sel.css(\"title::text\").re(r\"(\\w+) to (\\w+)\"))\n",
    "\n",
    "print(sel.xpath(\"//title\"))\n",
    "print(sel.xpath(\"//title/text()\").get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>\n",
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "Albert Einstein\n",
      "['change', 'deep-thoughts', 'thinking', 'world']\n",
      "{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}\n",
      "{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}\n",
      "{'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein', 'tags': ['inspirational', 'life', 'live', 'miracle', 'miracles']}\n",
      "{'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'author': 'Jane Austen', 'tags': ['aliteracy', 'books', 'classic', 'humor']}\n",
      "{'text': \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'author': 'Marilyn Monroe', 'tags': ['be-yourself', 'inspirational']}\n",
      "{'text': '“Try not to become a man of success. Rather become a man of value.”', 'author': 'Albert Einstein', 'tags': ['adulthood', 'success', 'value']}\n",
      "{'text': '“It is better to be hated for what you are than to be loved for what you are not.”', 'author': 'André Gide', 'tags': ['life', 'love']}\n",
      "{'text': \"“I have not failed. I've just found 10,000 ways that won't work.”\", 'author': 'Thomas A. Edison', 'tags': ['edison', 'failure', 'inspirational', 'paraphrased']}\n",
      "{'text': \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", 'author': 'Eleanor Roosevelt', 'tags': ['misattributed-eleanor-roosevelt']}\n",
      "{'text': '“A day without sunshine is like, you know, night.”', 'author': 'Steve Martin', 'tags': ['humor', 'obvious', 'simile']}\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "import requests\n",
    "\n",
    "url = \"https://quotes.toscrape.com\"\n",
    "html = requests.get(url).content\n",
    "\n",
    "sel = scrapy.Selector(text=html)\n",
    "\n",
    "quote = sel.css(\"div.quote\")[0]\n",
    "print(quote)\n",
    "text = quote.css(\"span.text::text\").get()\n",
    "print(text)\n",
    "author = quote.css(\"small.author::text\").get()\n",
    "print(author)\n",
    "tags = quote.css(\"div.tags a.tag::text\").getall()\n",
    "print(tags)\n",
    "\n",
    "for quote in sel.css(\"div.quote\"):\n",
    "    text = quote.css(\"span.text::text\").get()\n",
    "    author = quote.css(\"small.author::text\").get()\n",
    "    tags = quote.css(\"div.tags a.tag::text\").getall()\n",
    "    print(dict(text=text, author=author, tags=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./tutorial/tutorial/spiders/quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\",\n",
    "        \"https://quotes.toscrape.com/page/2/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"text\": quote.css(\"span.text::text\").get(),\n",
    "                \"author\": quote.css(\"small.author::text\").get(),\n",
    "                \"tags\": quote.css(\"div.tags a.tag::text\").getall()\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ./tutorial\n",
    "scrapy crawl quotes -O ./tutorial/data/quotes.json\n",
    "scrapy crawl quotes -o ./tutorial/data/quotes.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/page/2/\n",
      "/page/2/\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "import requests\n",
    "\n",
    "url = \"https://quotes.toscrape.com\"\n",
    "html = requests.get(url).content\n",
    "\n",
    "sel = scrapy.Selector(text=html)\n",
    "next = sel.css(\"li.next a::attr(href)\").get()\n",
    "print(next)\n",
    "next = sel.css(\"li.next a\").attrib[\"href\"]\n",
    "print(next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./tutorial/tutorial/spiders/quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"text\": quote.css(\"span.text::text\").get(),\n",
    "                \"author\": quote.css(\"small.author::text\").get(),\n",
    "                \"tags\": quote.css(\"div.tags a.tag::text\").getall()\n",
    "            }\n",
    "\n",
    "        next_page = response.css(\"li.next a::attr(href)\").get()\n",
    "        if next_page is not None:\n",
    "            next_page = response.urljoin(next_page)\n",
    "            yield scrapy.Request(next_page, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ./tutorial\n",
    "scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./tutorial/tutorial/spiders/quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuatesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"text\": quote.css(\"span.text::text\").get(),\n",
    "                \"author\": quote.css(\"span small::text\").get(),\n",
    "                \"tags\": quote.css(\"div.tags a.tag::text\").getall()\n",
    "            }\n",
    "\n",
    "        next_page = response.css(\"li.next a::attr(href)\").get()\n",
    "        if next_page is not None:\n",
    "            yield response.follow(next_page, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ./tutorial\n",
    "scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./tutorial/tutorial/spiders/quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"text\": quote.css(\"span.text::text\").get(),\n",
    "                \"author\": quote.css(\"span small::text\").get(),\n",
    "                \"tags\": quote.css(\"div.tags a.tag::text\").getall()\n",
    "            }\n",
    "\n",
    "        for href in response.css(\"ul.pager a::attr(href)\"):\n",
    "            yield response.follow(href, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ./tutorial\n",
    "scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./tutorial/tutorial/spiders/quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"text\": quote.css(\"span.text::text\").get(),\n",
    "                \"author\": quote.css(\"span small::text\").get(),\n",
    "                \"tags\": quote.css(\"div.tags a.tag::text\").getall()\n",
    "            }\n",
    "\n",
    "        for a in response.css(\"ul.pager a\"):\n",
    "            yield response.follow(a, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ./tutorial\n",
    "scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./tutorial/tutorial/spiders/quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"text\": quote.css(\"span.text::text\").get(),\n",
    "                \"author\": quote.css(\"span small::text\").get(),\n",
    "                \"tags\": quote.css(\"div.tags a.tag::text\").getall()\n",
    "            }\n",
    "\n",
    "        yield from response.follow_all(css=\"ul.pager a\", callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ./tutorial\n",
    "scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./tutorial/tutorial/spiders/author_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/author_spider.py\n",
    "import scrapy\n",
    "\n",
    "class AuthorSpider(scrapy.Spider):\n",
    "    name = \"author\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        author_page_links = response.css(\".author + a\")\n",
    "        yield from response.follow_all(author_page_links, callback=self.parse_author)\n",
    "\n",
    "        pagination_links = response.css(\"li.next a\")\n",
    "        yield from response.follow_all(pagination_links, callback=self.parse)\n",
    "\n",
    "    def parse_author(self, response):\n",
    "        def extract_with_css(query):\n",
    "            return response.css(query).get(default=\"\").strip()\n",
    "\n",
    "        yield {\n",
    "            \"name\": extract_with_css(\"h3.author-title::text\"),\n",
    "            \"birthdate\": extract_with_css(\".author-born-date::text\"),\n",
    "            \"bio\": extract_with_css(\".author-description::text\")\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ./tutorial\n",
    "scrapy crawl author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./tutorial/tutorial/spiders/quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        url = \"https://quotes.toscrape.com/\"\n",
    "        tag = getattr(self, \"tag\", None)\n",
    "        if tag is not None:\n",
    "            url = url + \"tag/\" + tag\n",
    "        yield scrapy.Request(url, self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                \"text\": quote.css(\"span.text::text\").get(),\n",
    "                \"author\": quote.css(\"small.author::text\").get()\n",
    "            }\n",
    "\n",
    "        next_page = response.css(\"li.next a::attr(href)\").get()\n",
    "        if next_page is not None:\n",
    "            yield response.follow(next_page, self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ./tutorial\n",
    "scrapy crawl quotes -O ./tutorial/data/quotes-humor.json -a tag=humor"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Scrapy",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
