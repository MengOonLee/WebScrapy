{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MengOonLee/Web_scraping/blob/master/Tutorial/Scrapy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvXGXei0CJFI"
   },
   "source": [
    "# Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vi9PaP1PCJFN"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip install --no-cache-dir -qU scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUWOvXRPCJFT",
    "outputId": "bbd7102d-66fb-43b1-cfd0-e00574a76ce2",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Jane Austen\n",
      "Text: “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "Next page: /tag/humor/page/2/\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "import requests\n",
    "url = \"https://quotes.toscrape.com/tag/humor/\"\n",
    "html = requests.get(url).content\n",
    "\n",
    "sel = scrapy.Selector(text=html)\n",
    "quote = sel.css('div.quote')\n",
    "author = quote.xpath('span/small/text()').get()\n",
    "print('Author:', author)\n",
    "text = quote.css('span.text::text').get()\n",
    "print('Text:', text)\n",
    "\n",
    "next_page = sel.css('li.next a::attr(href)').get()\n",
    "print('Next page:', next_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lEgazWXOCJFQ",
    "outputId": "2683890a-032c-4068-cae9-0398a2745daa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'tutorial', using template directory '/Work/venv/lib/python3.8/site-packages/scrapy/templates/project', created in:\n",
      "    /Work/Web_scraping/Tutorial/tutorial\n",
      "\n",
      "You can start your first spider with:\n",
      "    cd tutorial\n",
      "    scrapy genspider example example.com\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "scrapy startproject tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AN4jZIGICJFV",
    "outputId": "a9da73a1-4f78-4449-836f-f7e1408c0d6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./tutorial/quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tutorial/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = 'quotes'\n",
    "    start_urls = [\n",
    "        'https://quotes.toscrape.com/tag/humor/'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'author': quote.xpath('span/small/text()').get(),\n",
    "                'text': quote.css('span.text::text').get()\n",
    "            }\n",
    "\n",
    "        next_page = response.css('li.next a::attr(href)').get()\n",
    "        if next_page is not None:\n",
    "            yield response.follow(next_page, self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "-lYj3sx7CJFY",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "fc28524c-96e9-480f-9aab-eede01ad8986",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 14:51:34 [scrapy.utils.log] INFO: Scrapy 2.10.1 started (bot: scrapybot)\n",
      "2023-09-10 14:51:34 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.8.10 (default, May 26 2023, 14:05:08) - [GCC 9.4.0], pyOpenSSL 23.2.0 (OpenSSL 3.1.2 1 Aug 2023), cryptography 41.0.3, Platform Linux-6.2.0-31-generic-x86_64-with-glibc2.29\n",
      "2023-09-10 14:51:34 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2023-09-10 14:51:34 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'SPIDER_LOADER_WARN_ONLY': True}\n",
      "2023-09-10 14:51:34 [py.warnings] WARNING: /Work/venv/lib/python3.8/site-packages/scrapy/utils/request.py:248: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2023-09-10 14:51:34 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2023-09-10 14:51:34 [scrapy.extensions.telnet] INFO: Telnet Password: cde5a02da468f50d\n",
      "2023-09-10 14:51:34 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2023-09-10 14:51:34 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2023-09-10 14:51:34 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2023-09-10 14:51:34 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2023-09-10 14:51:34 [scrapy.core.engine] INFO: Spider opened\n",
      "2023-09-10 14:51:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-09-10 14:51:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2023-09-10 14:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/tag/humor/> (referer: None)\n",
      "2023-09-10 14:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
      "{'author': 'Jane Austen', 'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”'}\n",
      "2023-09-10 14:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
      "{'author': 'Steve Martin', 'text': '“A day without sunshine is like, you know, night.”'}\n",
      "2023-09-10 14:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
      "{'author': 'Garrison Keillor', 'text': '“Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.”'}\n",
      "2023-09-10 14:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
      "{'author': 'Jim Henson', 'text': '“Beauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.”'}\n",
      "2023-09-10 14:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
      "{'author': 'Charles M. Schulz', 'text': \"“All you need is love. But a little chocolate now and then doesn't hurt.”\"}\n",
      "2023-09-10 14:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
      "{'author': 'Suzanne Collins', 'text': \"“Remember, we're madly in love, so it's all right to kiss me anytime you feel like it.”\"}\n",
      "2023-09-10 14:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
      "{'author': 'Charles Bukowski', 'text': '“Some people never go crazy. What truly horrible lives they must lead.”'}\n",
      "2023-09-10 14:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
      "{'author': 'Terry Pratchett', 'text': '“The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.”'}\n",
      "2023-09-10 14:51:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
      "{'author': 'Dr. Seuss', 'text': '“Think left and think right and think low and think high. Oh, the thinks you can think up if only you try!”'}\n",
      "2023-09-10 14:51:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/>\n",
      "{'author': 'George Carlin', 'text': '“The reason I talk to myself is because I’m the only one whose answers I accept.”'}\n",
      "2023-09-10 14:51:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/tag/humor/page/2/> (referer: https://quotes.toscrape.com/tag/humor/)\n",
      "2023-09-10 14:51:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/page/2/>\n",
      "{'author': 'W.C. Fields', 'text': '“I am free of all prejudice. I hate everyone equally. ”'}\n",
      "2023-09-10 14:51:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/tag/humor/page/2/>\n",
      "{'author': 'Jane Austen', 'text': \"“A lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.”\"}\n",
      "2023-09-10 14:51:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2023-09-10 14:51:36 [scrapy.extensions.feedexport] INFO: Stored jl feed (12 items) in: ./data/quotes.jl\n",
      "2023-09-10 14:51:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 528,\n",
      " 'downloader/request_count': 2,\n",
      " 'downloader/request_method_count/GET': 2,\n",
      " 'downloader/response_bytes': 15667,\n",
      " 'downloader/response_count': 2,\n",
      " 'downloader/response_status_count/200': 2,\n",
      " 'elapsed_time_seconds': 1.749888,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2023, 9, 10, 14, 51, 36, 391985),\n",
      " 'item_scraped_count': 12,\n",
      " 'log_count/DEBUG': 15,\n",
      " 'log_count/INFO': 11,\n",
      " 'log_count/WARNING': 1,\n",
      " 'memusage/max': 57995264,\n",
      " 'memusage/startup': 57995264,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 2,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2023, 9, 10, 14, 51, 34, 642097)}\n",
      "2023-09-10 14:51:36 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "scrapy runspider ./tutorial/quotes_spider.py -O ./data/quotes.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIeH3gbpFNwQ",
    "outputId": "12c4a9ef-1052-4731-8090-7d0c27c8705c"
   },
   "outputs": [],
   "source": [
    "%%writefile ./Tutorial/Tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        \"https://quotes.toscrape.com/page/1/\",\n",
    "        \"https://quotes.toscrape.com/page/2/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = f'./data/quotes-{page}.html'\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Ck1_F6jFD53",
    "outputId": "655e1795-902a-4246-fc43-8218aebd00d6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./Tutorial/run.sh\n",
    "#!/bin/bash\n",
    "\n",
    "scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqcv_k7tCJFn",
    "outputId": "a8362a3d-e257-4fce-f39e-f2e69678eb3c"
   },
   "outputs": [],
   "source": [
    "from scrapy import Selector\n",
    "import requests\n",
    "\n",
    "url = \"https://quotes.toscrape.com/page/1/\"\n",
    "html = requests.get(url).content\n",
    "\n",
    "sel = Selector(text=html)\n",
    "# CSS\n",
    "title = sel.css('title::text')\n",
    "print(f\"css title: {title}\")\n",
    "print(title.re(r'(\\w+) to (\\w+)'))\n",
    "\n",
    "# XPath\n",
    "title = sel.xpath('//title/text()')\n",
    "print(f\"xpath title: {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E2o-JD25CJFp",
    "outputId": "3df0327a-9d9d-4fb6-e168-b63d7f1e2517",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scrapy import Selector\n",
    "import requests\n",
    "\n",
    "url = \"https://quotes.toscrape.com/\"\n",
    "html = requests.get(url).content\n",
    "\n",
    "sel = Selector(text=html)\n",
    "\n",
    "for quote in sel.css('div.quote'):\n",
    "    text = quote.css('span.text::text').extract_first()\n",
    "    author = quote.css('small.author::text').extract_first()\n",
    "    tags = quote.css('div.tags a.tag::text').extract()\n",
    "    print(dict(text=text, author=author, tags=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0SnvXeOJt3KK",
    "outputId": "90a06139-1b97-45a6-fefc-4a1271211cf7"
   },
   "outputs": [],
   "source": [
    "%%writefile ./Tutorial/Tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "      'https://quotes.toscrape.com/page/1/',\n",
    "      'https://quotes.toscrape.com/page/2/'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall()\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBmQ1PfP6SDC",
    "outputId": "35af10e9-bec4-4e9f-d85b-ab4f689819d5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./Tutorial/run.sh\n",
    "#!/bin/bash\n",
    "\n",
    "scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aFigT5eCJFr"
   },
   "source": [
    "### Storing the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "roz26Udn6cDj",
    "outputId": "efd1e2ec-fdc1-43a0-f770-ba15cf448dc3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./Tutorial/run.sh\n",
    "#!/bin/bash\n",
    "\n",
    "scrapy crawl quotes -O ./data/quotes.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ok8vKftv7dDq",
    "outputId": "964b3726-9cf6-4ce4-c96e-51323207b78d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./Tutorial/run.sh\n",
    "#!/bin/bash\n",
    "\n",
    "scrapy crawl quotes -o ./data/quotes.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kzp4uildCJFv"
   },
   "source": [
    "## Following links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzhbQfBkCJFw",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "scrapy shell \"https://quotes.toscrape.com\"\n",
    "response.css(\"li.next a\").get()\n",
    "response.css(\"li.next a::attr(href)\").get()\n",
    "response.css(\"li.next a\").attrib[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gJ_J7N1CJFw"
   },
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "      'https://quotes.toscrape.com/page/1/'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall()\n",
    "            }\n",
    "        next_page = response.css('li.next a::attr(href)').get()\n",
    "        if next_page is not None:\n",
    "            next_page = response.urljoin(next_page)\n",
    "            yield scrapy.Request(next_page, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acmICjxSCJFx",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "rm -rf tutorial/quotes.jl\n",
    "scrapy crawl quotes -o quotes.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Moiw3bkNCJFy"
   },
   "source": [
    "### Supports relative URLs directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSrsFY4pCJFz"
   },
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'https://quotes.toscrape.com/page/1/'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall()\n",
    "            }\n",
    "        next_page = response.css('li.next a::attr(href)').get()\n",
    "        if next_page is not None:\n",
    "            yield response.follow(next_page, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66jeaDK8CJFz",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "rm -rf tutorial/quotes.jl\n",
    "scrapy crawl quotes -o quotes.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXeh8nZ2CJF0"
   },
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'https://quotes.toscrape.com'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall()\n",
    "            }\n",
    "        for href in response.css('li.next a::attr(href)'):\n",
    "            yield response.follow(href, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zz8tx-EqCJF0",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "rm -rf tutorial/quotes.jl\n",
    "scrapy crawl quotes -o quotes.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQB5CAhDCJF1"
   },
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'https://quotes.toscrape.com'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall()\n",
    "            }\n",
    "        for a in response.css('ul.pager li.next a'):\n",
    "            yield response.follow(a, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKjNALacCJF1",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "rm -rf tutorial/quotes.jl\n",
    "scrapy crawl quotes -o quotes.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9kHIFzPCJF2"
   },
   "source": [
    "### Create multiple requests from an iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6dqwRX-CJF3"
   },
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'https://quotes.toscrape.com'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall()\n",
    "            }\n",
    "        anchors = response.css('ul.pager li.next a')\n",
    "        yield from response.follow_all(anchors, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBY4_jlgCJF4",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "rm -rf tutorial/quotes.jl\n",
    "scrapy crawl quotes -o quotes.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCTtEFJ4CJF5"
   },
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'https://quotes.toscrape.com'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall()\n",
    "            }\n",
    "        yield from response.follow_all(css='ul.pager li.next a', callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTDBh7ZFCJF5",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tutorial\n",
    "rm -rf tutorial/quotes.jl\n",
    "scrapy crawl quotes -o quotes.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1_jnBpXCJF5"
   },
   "source": [
    "## More patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3ChZ_6SCJF5"
   },
   "outputs": [],
   "source": [
    "%%writefile ./tutorial/tutorial/spiders/author_spider.py\n",
    "import scrapy\n",
    "\n",
    "class AuthorSpider(scrapy.Spider):\n",
    "    name = 'author'\n",
    "\n",
    "    start_urls = ['https://quotes.toscrape.com/']\n",
    "\n",
    "    def parse(self, response):\n",
    "        author_page_links = response.css('.author + a')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Scrapy",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
