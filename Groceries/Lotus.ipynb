{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/WebScrapy/blob/master/Groceries/Lotus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I3g1lntAeoPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "721cb651-9e05-4afb-8d36-4726040043c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.2/43.2 kB 4.1 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 290.1/290.1 kB 13.3 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.4/9.4 MB 125.7 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 476.0/476.0 kB 188.6 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 167.8 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 254.1/254.1 kB 256.7 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.6/97.6 kB 202.8 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.6/42.6 kB 177.5 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 74.6/74.6 kB 204.3 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 104.5 MB/s eta 0:00:00\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip install --no-cache-dir -qU scrapy selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpckwD6FYG2Y",
        "outputId": "2007f5b3-da7f-41a4-ced6-be970e9e6e09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Lotus.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile Lotus.py\n",
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "import scrapy\n",
        "from scrapy import crawler, loader\n",
        "from itemloaders import processors\n",
        "import logging\n",
        "logging.disable(\"WARNING\")\n",
        "\n",
        "class LotusItem(scrapy.Item):\n",
        "    category = scrapy.Field(output_processor=processors.TakeFirst())\n",
        "    name = scrapy.Field(output_processor=processors.TakeFirst())\n",
        "    price = scrapy.Field(output_processor=processors.TakeFirst())\n",
        "    info = scrapy.Field()\n",
        "\n",
        "class LotusSpider(scrapy.Spider):\n",
        "    name = 'Lotus'\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        options = webdriver.chrome.options.Options()\n",
        "        options.add_argument(\"--headless\")\n",
        "        options.add_argument(\"--no-sandbox\")\n",
        "        options.add_argument(\"--enable-javascript\")\n",
        "        options.add_argument(\"--enable-cookies\")\n",
        "        options.add_argument(\"--disable-notifications\")\n",
        "        options.add_argument(\"--disable-web-security\")\n",
        "        options.add_argument(\"--incognito\")\n",
        "        self.driver = webdriver.Chrome(options=options)\n",
        "        self.collector = loader.ItemLoader(item=LotusItem())\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            \"https://www.lotuss.com.my/en/category/meat-poultry/meat/parts-weighted\"\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse_items)\n",
        "\n",
        "    def parse_items(self, response):\n",
        "        self.driver.get(response.url)\n",
        "\n",
        "        elem_present = \"\"\n",
        "        while not elem_present:\n",
        "            try:\n",
        "                elem_present = self.driver.find_element(By.XPATH,\n",
        "                    \"//div[@class='product-grid-item']\"\n",
        "                )\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        selector = scrapy.Selector(text=self.driver.page_source)\n",
        "        category = selector.css(\"h1#category-title::text\").get()\n",
        "        self.collector.add_value(\"category\", category)\n",
        "\n",
        "        category_url = selector.css(\"div.carousel a\")\n",
        "        if len(category_url)!=0:\n",
        "            yield from response.follow_all(category_url,\n",
        "                callback=self.parse_items)\n",
        "\n",
        "        else:\n",
        "            last_height = self.driver.execute_script(\n",
        "                \"return document.body.scrollHeight\"\n",
        "            )\n",
        "\n",
        "            while True:\n",
        "                self.driver.execute_script(\n",
        "                    \"window.scrollTo(0, document.body.scrollHeight)\"\n",
        "                )\n",
        "                time.sleep(3)\n",
        "                new_height = self.driver.execute_script(\n",
        "                    \"return document.body.scrollHeight\"\n",
        "                )\n",
        "                if new_height==last_height:\n",
        "                    break\n",
        "                last_height = new_height\n",
        "\n",
        "            selector = scrapy.Selector(text=self.driver.page_source)\n",
        "            items = selector.css(\"div.product-grid-item\")\n",
        "            for item in items:\n",
        "                name = item.css(\"a#product-title::text\").get()\n",
        "                self.collector.add_value(\"name\", name)\n",
        "\n",
        "                price = item.css(\"p\")[0].css(\"::text\").getall()\n",
        "                self.collector.add_value(\"price\", \"\".join(price))\n",
        "\n",
        "            print(self.collector.load_item())\n",
        "\n",
        "                # img_url = item.css(\"img::attr(src)\").get()\n",
        "\n",
        "                # info_page = item.css(\"a::attr(href)\").get()\n",
        "                # if info_page is not None:\n",
        "                #     yield response.follow(info_page,\n",
        "                #         callback=self.parse_info)\n",
        "\n",
        "                # return l.load_item()\n",
        "\n",
        "            # info_links = selector.css(\"div#product-list a\")\n",
        "            # yield from response.follow_all(info_links,\n",
        "            #     callback=self.parse_info)\n",
        "\n",
        "    # def parse_info(self, response):\n",
        "    #     self.driver.get(response.url)\n",
        "\n",
        "    #     selector = scrapy.Selector(text=self.driver.page_source)\n",
        "    #     info = selector.css(\"div.MuiBox-root::text\")[2].get()\n",
        "    #     print(info)\n",
        "    #     yield info\n",
        "\n",
        "\n",
        "process = crawler.CrawlerProcess()\n",
        "process.crawl(LotusSpider)\n",
        "process.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J_TorfYlmX5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed660d6-8f96-4c4a-a721-e30b5338382f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'category': 'Parts & Weighted',\n",
            " 'name': \"LOTUS'S FRESH AUS LAMB SHOULDER SLICE (5319)\",\n",
            " 'price': 'RM28.97/Kg'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
            "\n",
            "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
            "\n",
            "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
            "  return cls(crawler)\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "python Lotus.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCTxoAzBKrikBB1OKaRPL0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}