{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/WebScrapy/blob/master/Groceries/Lotus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install --no-cache-dir -U scrapy selenium"
      ],
      "metadata": {
        "id": "pn3wEMOnJXnS",
        "collapsed": true,
        "outputId": "df5fa04b-5a85-491f-c080-c919b379a2fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scrapy in /usr/local/lib/python3.10/dist-packages (2.11.2)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.25.0)\n",
            "Requirement already satisfied: Twisted>=18.9.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (24.7.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (43.0.1)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from scrapy) (1.2.0)\n",
            "Requirement already satisfied: itemloaders>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from scrapy) (1.3.2)\n",
            "Requirement already satisfied: parsel>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (1.9.1)\n",
            "Requirement already satisfied: pyOpenSSL>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (24.2.1)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scrapy) (1.7.0)\n",
            "Requirement already satisfied: service-identity>=18.1.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (24.1.0)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (2.2.1)\n",
            "Requirement already satisfied: zope.interface>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (7.0.3)\n",
            "Requirement already satisfied: protego>=0.1.15 in /usr/local/lib/python3.10/dist-packages (from scrapy) (0.3.1)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from scrapy) (71.0.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from scrapy) (24.1)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.10/dist-packages (from scrapy) (5.1.2)\n",
            "Requirement already satisfied: lxml>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from scrapy) (4.9.4)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from scrapy) (0.7.1)\n",
            "Requirement already satisfied: PyDispatcher>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from scrapy) (2.0.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.26.2)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.8.30)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->scrapy) (1.17.1)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.10/dist-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (24.2.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (0.4.1)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: automat>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from Twisted>=18.9.0->scrapy) (24.8.1)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.10/dist-packages (from Twisted>=18.9.0->scrapy) (23.10.4)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.10/dist-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
            "Requirement already satisfied: incremental>=24.7.0 in /usr/local/lib/python3.10/dist-packages (from Twisted>=18.9.0->scrapy) (24.7.2)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (2.32.3)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (2.1.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (3.16.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.22)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from incremental>=24.7.0->Twisted>=18.9.0->scrapy) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (3.3.2)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpckwD6FYG2Y",
        "outputId": "e033c060-b845-49d1-a95b-201e8cd7c14a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting Lotus.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile Lotus.py\n",
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support import wait, expected_conditions\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "import scrapy\n",
        "from scrapy import crawler, loader\n",
        "from itemloaders import processors\n",
        "import logging\n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "class LotusItem(scrapy.Item):\n",
        "    categories = scrapy.Field()\n",
        "    name = scrapy.Field(output_processor=processors.TakeFirst())\n",
        "    price = scrapy.Field(output_processor=processors.TakeFirst())\n",
        "    info = scrapy.Field(output_processor=processors.TakeFirst())\n",
        "\n",
        "class LotusLoader(loader.ItemLoader):\n",
        "    item = LotusItem()\n",
        "\n",
        "class LotusSpider(scrapy.Spider):\n",
        "    name = 'Lotus'\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        options = webdriver.chrome.options.Options()\n",
        "        options.add_argument(\"--headless\")\n",
        "        options.add_argument(\"--no-sandbox\")\n",
        "        options.add_argument(\"--enable-javascript\")\n",
        "        options.add_argument(\"--enable-cookies\")\n",
        "        options.add_argument(\"--disable-notifications\")\n",
        "        options.add_argument(\"--disable-web-security\")\n",
        "        options.add_argument(\"--incognito\")\n",
        "        self.driver = webdriver.Chrome(options=options)\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            # \"https://www.lotuss.com.my/en/category/grocery/biscuits-cakes\"\n",
        "            \"https://www.lotuss.com.my/en/category/beverages/coffee-tea/instant-coffee\"\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            request = scrapy.Request(url=url, callback=self.parse_item)\n",
        "            yield request\n",
        "\n",
        "    def parse_item(self, response):\n",
        "        self.driver.get(response.url)\n",
        "        num_trial = 0\n",
        "        while num_trial < 3:\n",
        "            try:\n",
        "                if wait.WebDriverWait(self.driver, timeout=10)\\\n",
        "                    .until(expected_conditions.presence_of_element_located(\n",
        "                        (By.XPATH, \"//div[@id='product-list']\"))):\n",
        "                    break\n",
        "            except NoSuchElementException:\n",
        "                continue\n",
        "                num_trial += 1\n",
        "\n",
        "        selector = scrapy.Selector(text=self.driver.page_source)\n",
        "        categories_url = selector.css(\"div.carousel a\")\n",
        "\n",
        "        if len(categories_url)!=0:\n",
        "            yield from response.follow_all(categories_url,\n",
        "                callback=self.parse_items)\n",
        "\n",
        "        else:\n",
        "            last_height = self.driver.execute_script(\n",
        "                \"return document.body.scrollHeight\")\n",
        "\n",
        "            while True:\n",
        "                time.sleep(10)\n",
        "                self.driver.execute_script(\n",
        "                    \"window.scrollTo(0, document.body.scrollHeight)\")\n",
        "\n",
        "                new_height = self.driver.execute_script(\n",
        "                    \"return document.body.scrollHeight\")\n",
        "                if new_height==last_height:\n",
        "                    break\n",
        "                last_height = new_height\n",
        "\n",
        "            selector = scrapy.Selector(text=self.driver.page_source)\n",
        "\n",
        "            categories = selector.xpath(\n",
        "                \"//li[contains(@class, 'MuiBreadcrumbs-li')]//text()\"\n",
        "            ).getall()\n",
        "\n",
        "            for item in selector.css(\"div.product-grid-item\"):\n",
        "                loader = LotusLoader()\n",
        "                loader.add_value(\"categories\", categories)\n",
        "\n",
        "                name = item.css(\"a#product-title::text\").get()\n",
        "                loader.add_value(\"name\", name)\n",
        "\n",
        "                price = item.css(\"p\")[0].css(\"::text\").getall()\n",
        "                loader.add_value(\"price\", \"\".join(price))\n",
        "\n",
        "                info_page = item.css(\"a::attr(href)\").get()\n",
        "                if info_page is not None:\n",
        "                    yield response.follow(info_page,\n",
        "                        callback=self.parse_info, meta={\"loader\": loader})\n",
        "\n",
        "                # yield loader.load_item()\n",
        "\n",
        "                # img_url = item.css(\"img::attr(src)\").get()\n",
        "\n",
        "            # info_links = selector.css(\"div#product-list a\")\n",
        "            # yield from response.follow_all(info_links,\n",
        "            #     callback=self.parse_info)\n",
        "\n",
        "    def parse_info(self, response):\n",
        "        self.driver.get(response.url)\n",
        "        num_trial = 0\n",
        "        while num_trial < 3:\n",
        "            try:\n",
        "                if wait.WebDriverWait(self.driver, timeout=10)\\\n",
        "                    .until(expected_conditions.presence_of_element_located(\n",
        "                        (By.XPATH, \"//div[@id='scrollable-force-tabpanel-0']\"))):\n",
        "                    break\n",
        "            except NoSuchElementException:\n",
        "                continue\n",
        "                num_trial += 1\n",
        "\n",
        "        selector = scrapy.Selector(text=self.driver.page_source)\n",
        "        info = selector.css(\"div#scrollable-force-tabpanel-0 ::text\").get()\n",
        "        loader = response.meta[\"loader\"]\n",
        "        loader.add_value(\"info\", info)\n",
        "\n",
        "        yield loader.load_item()\n",
        "\n",
        "\n",
        "process = crawler.CrawlerProcess(\n",
        "    settings={\"FEEDS\":{\"items.jl\":{\"format\":\"jsonlines\"}}}\n",
        ")\n",
        "process.crawl(LotusSpider)\n",
        "process.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvHkdbKIJV9r",
        "outputId": "808f0121-edb9-44f5-b0ef-6db5d789e47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Lotus.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile Lotus.py\n",
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support import wait, expected_conditions\n",
        "import scrapy\n",
        "from scrapy import crawler, loader\n",
        "from itemloaders import processors\n",
        "import logging\n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "class LotusItem(scrapy.Item):\n",
        "    categories = scrapy.Field()\n",
        "    name = scrapy.Field(output_processor=processors.TakeFirst())\n",
        "    price = scrapy.Field(output_processor=processors.TakeFirst())\n",
        "    info = scrapy.Field(output_processor=processors.TakeFirst())\n",
        "\n",
        "class LotusLoader(loader.ItemLoader):\n",
        "    item = LotusItem()\n",
        "\n",
        "class LotusSpider(scrapy.Spider):\n",
        "    name = 'Lotus'\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        options = webdriver.chrome.options.Options()\n",
        "        options.add_argument(\"--headless\")\n",
        "        options.add_argument(\"--no-sandbox\")\n",
        "        options.add_argument(\"--enable-javascript\")\n",
        "        options.add_argument(\"--enable-cookies\")\n",
        "        options.add_argument(\"--disable-notifications\")\n",
        "        options.add_argument(\"--disable-web-security\")\n",
        "        options.add_argument(\"--incognito\")\n",
        "        self.driver = webdriver.Chrome(options=options)\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            # \"https://www.lotuss.com.my/en/category/grocery/commodities/rice\"\n",
        "            \"https://www.lotuss.com.my/en/category/meat-poultry\"\n",
        "        ]\n",
        "\n",
        "        for url in urls:\n",
        "            request = scrapy.Request(url=url, callback=self.parse_category)\n",
        "            yield request\n",
        "\n",
        "    def parse_category(self, response):\n",
        "        self.driver.get(response.url)\n",
        "\n",
        "        try:\n",
        "            wait.WebDriverWait(self.driver, timeout=10)\\\n",
        "                .until(expected_conditions.presence_of_element_located(\n",
        "                    (By.XPATH, \"//div[@class='carousel']\")))\n",
        "            selector = scrapy.Selector(text=self.driver.page_source)\n",
        "            category_urls = selector.css(\"div.carousel a\")\n",
        "            print(len(category_urls))\n",
        "\n",
        "            yield from response.follow_all(category_urls,\n",
        "                callback=self.parse_category)\n",
        "        except:\n",
        "            pass\n",
        "            print(\"Failed\")\n",
        "\n",
        "        # last_height = self.driver.execute_script(\n",
        "        #     \"return document.body.scrollHeight\")\n",
        "\n",
        "        # element = self.driver.find_element(By.XPATH,\n",
        "        #     \"//div[@id='product-list']\")\n",
        "        # self.driver.execute_script(\"\"\"\n",
        "        #     arguments[0].scrollTop = arguments[0].scrollTop + arguments[0].offsetHeight;\n",
        "        # \"\"\", element)\n",
        "        # self.driver.execute_script(\n",
        "        #     \"window.scrollTo(0, document.body.scrollHeight)\")\n",
        "        # time.sleep(20)\n",
        "\n",
        "        # new_height = self.driver.execute_script(\n",
        "        #     \"return document.body.scrollHeight\")\n",
        "        # print(last_height, new_height)\n",
        "\n",
        "        # while True:\n",
        "        #         time.sleep(10)\n",
        "        #         self.driver.execute_script(\n",
        "        #             \"window.scrollTo(0, document.body.scrollHeight)\")\n",
        "\n",
        "        #         new_height = self.driver.execute_script(\n",
        "        #             \"return document.body.scrollHeight\")\n",
        "        #         if new_height==last_height:\n",
        "        #             break\n",
        "        #         last_height = new_height\n",
        "        #     print(new_height)\n",
        "\n",
        "process = crawler.CrawlerProcess()\n",
        "process.crawl(LotusSpider)\n",
        "process.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "python Lotus.py"
      ],
      "metadata": {
        "id": "E_dK2apHKAPf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}