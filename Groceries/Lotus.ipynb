{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MengOonLee/WebScrapy/blob/master/Groceries/Lotus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LpckwD6FYG2Y",
    "outputId": "e033c060-b845-49d1-a95b-201e8cd7c14a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Lotus.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Lotus.py\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import wait, expected_conditions\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import scrapy\n",
    "from scrapy import crawler, loader\n",
    "from itemloaders import processors\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "class LotusItem(scrapy.Item):\n",
    "    categories = scrapy.Field()\n",
    "    name = scrapy.Field(output_processor=processors.TakeFirst())\n",
    "    price = scrapy.Field(output_processor=processors.TakeFirst())\n",
    "    info = scrapy.Field(output_processor=processors.TakeFirst())\n",
    "\n",
    "class LotusLoader(loader.ItemLoader):\n",
    "    item = LotusItem()\n",
    "\n",
    "class LotusSpider(scrapy.Spider):\n",
    "    name = 'Lotus'\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        options = webdriver.chrome.options.Options()\n",
    "        options.add_argument(\"--headless\")\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_argument(\"--enable-javascript\")\n",
    "        options.add_argument(\"--enable-cookies\")\n",
    "        options.add_argument(\"--disable-notifications\")\n",
    "        options.add_argument(\"--disable-web-security\")\n",
    "        options.add_argument(\"--incognito\")\n",
    "        self.driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = [\n",
    "            # \"https://www.lotuss.com.my/en/category/grocery/biscuits-cakes\"\n",
    "            \"https://www.lotuss.com.my/en/category/beverages/coffee-tea/instant-coffee\"\n",
    "        ]\n",
    "        \n",
    "        for url in urls:\n",
    "            request = scrapy.Request(url=url, callback=self.parse_item)\n",
    "            yield request\n",
    "\n",
    "    def parse_item(self, response):\n",
    "        self.driver.get(response.url)\n",
    "        num_trial = 0\n",
    "        while num_trial < 3:\n",
    "            try:\n",
    "                if wait.WebDriverWait(self.driver, timeout=10)\\\n",
    "                    .until(expected_conditions.presence_of_element_located(\n",
    "                        (By.XPATH, \"//div[@id='product-list']\"))):\n",
    "                    break\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "                num_trial += 1\n",
    "        \n",
    "        selector = scrapy.Selector(text=self.driver.page_source)\n",
    "        categories_url = selector.css(\"div.carousel a\")\n",
    "        \n",
    "        if len(categories_url)!=0:\n",
    "            yield from response.follow_all(categories_url,\n",
    "                callback=self.parse_items)\n",
    "\n",
    "        else:\n",
    "            last_height = self.driver.execute_script(\n",
    "                \"return document.body.scrollHeight\")\n",
    "            \n",
    "            while True:\n",
    "                time.sleep(10)\n",
    "                self.driver.execute_script(\n",
    "                    \"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "\n",
    "                new_height = self.driver.execute_script(\n",
    "                    \"return document.body.scrollHeight\")\n",
    "                if new_height==last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "            \n",
    "            selector = scrapy.Selector(text=self.driver.page_source)\n",
    "            \n",
    "            categories = selector.xpath(\n",
    "                \"//li[contains(@class, 'MuiBreadcrumbs-li')]//text()\"\n",
    "            ).getall()\n",
    "            \n",
    "            for item in selector.css(\"div.product-grid-item\"):\n",
    "                loader = LotusLoader()\n",
    "                loader.add_value(\"categories\", categories)\n",
    "                \n",
    "                name = item.css(\"a#product-title::text\").get()\n",
    "                loader.add_value(\"name\", name)\n",
    "\n",
    "                price = item.css(\"p\")[0].css(\"::text\").getall()\n",
    "                loader.add_value(\"price\", \"\".join(price))\n",
    "\n",
    "                info_page = item.css(\"a::attr(href)\").get()\n",
    "                if info_page is not None:\n",
    "                    yield response.follow(info_page,\n",
    "                        callback=self.parse_info, meta={\"loader\": loader})\n",
    "\n",
    "                # yield loader.load_item()\n",
    "\n",
    "                # img_url = item.css(\"img::attr(src)\").get()\n",
    "\n",
    "            # info_links = selector.css(\"div#product-list a\")\n",
    "            # yield from response.follow_all(info_links,\n",
    "            #     callback=self.parse_info)\n",
    "\n",
    "    def parse_info(self, response):\n",
    "        self.driver.get(response.url)\n",
    "        num_trial = 0\n",
    "        while num_trial < 3:\n",
    "            try:\n",
    "                if wait.WebDriverWait(self.driver, timeout=10)\\\n",
    "                    .until(expected_conditions.presence_of_element_located(\n",
    "                        (By.XPATH, \"//div[@id='scrollable-force-tabpanel-0']\"))):\n",
    "                    break\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "                num_trial += 1\n",
    "        \n",
    "        selector = scrapy.Selector(text=self.driver.page_source)\n",
    "        info = selector.css(\"div#scrollable-force-tabpanel-0 ::text\").get()\n",
    "        loader = response.meta[\"loader\"]\n",
    "        loader.add_value(\"info\", info)\n",
    "\n",
    "        yield loader.load_item()\n",
    "\n",
    "\n",
    "process = crawler.CrawlerProcess(\n",
    "    settings={\"FEEDS\":{\"items.jl\":{\"format\":\"jsonlines\"}}}\n",
    ")\n",
    "process.crawl(LotusSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Lotus.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Lotus.py\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import wait, expected_conditions\n",
    "import scrapy\n",
    "from scrapy import crawler, loader\n",
    "from itemloaders import processors\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "class LotusItem(scrapy.Item):\n",
    "    categories = scrapy.Field()\n",
    "    name = scrapy.Field(output_processor=processors.TakeFirst())\n",
    "    price = scrapy.Field(output_processor=processors.TakeFirst())\n",
    "    info = scrapy.Field(output_processor=processors.TakeFirst())\n",
    "\n",
    "class LotusLoader(loader.ItemLoader):\n",
    "    item = LotusItem()\n",
    "\n",
    "class LotusSpider(scrapy.Spider):\n",
    "    name = 'Lotus'\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        options = webdriver.chrome.options.Options()\n",
    "        options.add_argument(\"--headless\")\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_argument(\"--enable-javascript\")\n",
    "        options.add_argument(\"--enable-cookies\")\n",
    "        options.add_argument(\"--disable-notifications\")\n",
    "        options.add_argument(\"--disable-web-security\")\n",
    "        options.add_argument(\"--incognito\")\n",
    "        self.driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = [\n",
    "            # \"https://www.lotuss.com.my/en/category/grocery/biscuits-cakes\"\n",
    "            \"https://www.lotuss.com.my/en/category/beverages/coffee-tea/local-coffee\"\n",
    "        ]\n",
    "        \n",
    "        for url in urls:\n",
    "            request = scrapy.Request(url=url, callback=self.parse_category)\n",
    "            yield request\n",
    "\n",
    "    def parse_category(self, response):\n",
    "        self.driver.get(response.url)\n",
    "\n",
    "        try:\n",
    "            wait.WebDriverWait(self.driver, timeout=10)\\\n",
    "                .until(expected_conditions.presence_of_element_located(\n",
    "                    (By.XPATH, \"//div[@class='carousel']\")))\n",
    "            selector = scrapy.Selector(text=self.driver.page_source)\n",
    "            category_urls = selector.css(\"div.carousel a\")\n",
    "\n",
    "            yield from response.follow_all(category_urls,\n",
    "                callback=self.parse_category)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        last_height = self.driver.execute_script(\n",
    "            \"return document.body.scrollHeight\")\n",
    "        print(last_height)\n",
    "            \n",
    "        while True:\n",
    "        #         time.sleep(10)\n",
    "        #         self.driver.execute_script(\n",
    "        #             \"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "\n",
    "        #         new_height = self.driver.execute_script(\n",
    "        #             \"return document.body.scrollHeight\")\n",
    "        #         if new_height==last_height:\n",
    "        #             break\n",
    "        #         last_height = new_height\n",
    "        #     print(new_height)\n",
    "\n",
    "process = crawler.CrawlerProcess()\n",
    "process.crawl(LotusSpider)\n",
    "process.start()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOEy+ogCvkgS+3T6/mzrtkk",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
